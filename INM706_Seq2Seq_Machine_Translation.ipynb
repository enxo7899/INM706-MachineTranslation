{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN9HbTjhPr4J+vJeLtsyrHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16f491e58a494e2a964f8105539bcb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_665cb2fe4ee649b4ac501415bac89335",
              "IPY_MODEL_06bed08f801e485a953b8d79f8d73768",
              "IPY_MODEL_ab4d61ac86604f7d8c3cd509e54f9545"
            ],
            "layout": "IPY_MODEL_d671449a50c0493c897896998e4b6438"
          }
        },
        "665cb2fe4ee649b4ac501415bac89335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19dabbcad139492782623b7fa90cd7ee",
            "placeholder": "​",
            "style": "IPY_MODEL_dba331c4867140deb8cbbcf5eda85b84",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "06bed08f801e485a953b8d79f8d73768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83082077696c4b49ac47cb6a6230774a",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_594a9117ddce4f469cfb13e74138b261",
            "value": 42
          }
        },
        "ab4d61ac86604f7d8c3cd509e54f9545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b1120d0a8843fc8eb14a1b47db5d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_9252e89556db454898b31170c756e602",
            "value": " 42.0/42.0 [00:00&lt;00:00, 3.38kB/s]"
          }
        },
        "d671449a50c0493c897896998e4b6438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19dabbcad139492782623b7fa90cd7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba331c4867140deb8cbbcf5eda85b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83082077696c4b49ac47cb6a6230774a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "594a9117ddce4f469cfb13e74138b261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88b1120d0a8843fc8eb14a1b47db5d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9252e89556db454898b31170c756e602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb6023ad7e64d7eae56a1ec7b1cca12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98cbc35627104e3bab43a7fd0d941d96",
              "IPY_MODEL_164ce3f036b74e389198a5540821dca4",
              "IPY_MODEL_2085d37107d649a9a799f23bcce445d2"
            ],
            "layout": "IPY_MODEL_24a39f272fca4cdcbad792a4747c3ed9"
          }
        },
        "98cbc35627104e3bab43a7fd0d941d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08dc7d5f6943421e934e4b8e51cd7ac3",
            "placeholder": "​",
            "style": "IPY_MODEL_5dcc1c91a710438497f8097a558d428b",
            "value": "source.spm: 100%"
          }
        },
        "164ce3f036b74e389198a5540821dca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8852d0854a9946878ae2cb6ec0e75c67",
            "max": 804616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9231409402134d69956f5044c65ec163",
            "value": 804616
          }
        },
        "2085d37107d649a9a799f23bcce445d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312cf306ad5441e0a05020846656e1d3",
            "placeholder": "​",
            "style": "IPY_MODEL_72dedb0bdaf74a0c93efe79b873fe432",
            "value": " 805k/805k [00:00&lt;00:00, 845kB/s]"
          }
        },
        "24a39f272fca4cdcbad792a4747c3ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08dc7d5f6943421e934e4b8e51cd7ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcc1c91a710438497f8097a558d428b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8852d0854a9946878ae2cb6ec0e75c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9231409402134d69956f5044c65ec163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "312cf306ad5441e0a05020846656e1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72dedb0bdaf74a0c93efe79b873fe432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9653cd0864e4887b024018424fed75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2795d17c40f04980b8c0c4c5ca33d4ef",
              "IPY_MODEL_6ef5cf6430b047e39f8f0e7f2f63193f",
              "IPY_MODEL_d00c591ee60846a18fc689c6b4f976ec"
            ],
            "layout": "IPY_MODEL_4328b57524cd45b8909f0ba5e1f4dcd6"
          }
        },
        "2795d17c40f04980b8c0c4c5ca33d4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5451d7bd8bf1466e8d54fe2d47b56eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3c9418be494e1fa8d709f26656d89a",
            "value": "target.spm: 100%"
          }
        },
        "6ef5cf6430b047e39f8f0e7f2f63193f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0207c319f05b423a87e0ef988e5621f7",
            "max": 822211,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d17c8c90d954b8e8f48f101b8f8360e",
            "value": 822211
          }
        },
        "d00c591ee60846a18fc689c6b4f976ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680a19b174a2449bbc634f0e3965bf71",
            "placeholder": "​",
            "style": "IPY_MODEL_cbddc0d652784b50a0228b50f74dbcd4",
            "value": " 822k/822k [00:00&lt;00:00, 1.15MB/s]"
          }
        },
        "4328b57524cd45b8909f0ba5e1f4dcd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5451d7bd8bf1466e8d54fe2d47b56eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3c9418be494e1fa8d709f26656d89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0207c319f05b423a87e0ef988e5621f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d17c8c90d954b8e8f48f101b8f8360e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "680a19b174a2449bbc634f0e3965bf71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbddc0d652784b50a0228b50f74dbcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a682fbd83114de0948082510749024f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d45dbe9dfa8474c891dcede6dd4cf03",
              "IPY_MODEL_d2634e2d1d0049c89c950df42ce1f0d7",
              "IPY_MODEL_733d5334df13470aa722e0a002a99a0d"
            ],
            "layout": "IPY_MODEL_7e4b277217ca41579fb2e32507c5c960"
          }
        },
        "2d45dbe9dfa8474c891dcede6dd4cf03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97516e127d9d41da8da679b8b8e034a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8c056ec346da4824b54cd3bde01831cb",
            "value": "vocab.json: 100%"
          }
        },
        "d2634e2d1d0049c89c950df42ce1f0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b8e5f5326f74cb79003a67a2342a771",
            "max": 1383791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28b9bacc60134dd39355ba165e9e15da",
            "value": 1383791
          }
        },
        "733d5334df13470aa722e0a002a99a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f098b7ac2cfe4b0a966c57136488e5af",
            "placeholder": "​",
            "style": "IPY_MODEL_8d22846459b64798990cd58eac6a6a09",
            "value": " 1.38M/1.38M [00:01&lt;00:00, 1.17MB/s]"
          }
        },
        "7e4b277217ca41579fb2e32507c5c960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97516e127d9d41da8da679b8b8e034a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c056ec346da4824b54cd3bde01831cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8e5f5326f74cb79003a67a2342a771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b9bacc60134dd39355ba165e9e15da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f098b7ac2cfe4b0a966c57136488e5af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d22846459b64798990cd58eac6a6a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49f7b6f4839f46a6af436170df544067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6736f9ea51ca41f4935b30fd7f440834",
              "IPY_MODEL_43b686666041420f8993c79cec8d251b",
              "IPY_MODEL_64eac4a88c6a47bb95a11e60438530c3"
            ],
            "layout": "IPY_MODEL_834321d10934449db30e2c072d32a48a"
          }
        },
        "6736f9ea51ca41f4935b30fd7f440834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca70b3fa2524a5c85fe302c8975c05e",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7b95d9889844e6997e39181043be00",
            "value": "config.json: 100%"
          }
        },
        "43b686666041420f8993c79cec8d251b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f99ea3a4bdc47a49b3f4ec4f549f89b",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f8a35595d7d4662a91b6eb063542cc4",
            "value": 1381
          }
        },
        "64eac4a88c6a47bb95a11e60438530c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f08232af4f874ba68a99ffd402394549",
            "placeholder": "​",
            "style": "IPY_MODEL_ee6b63b1844c49359aa3b648e5123ba6",
            "value": " 1.38k/1.38k [00:00&lt;00:00, 131kB/s]"
          }
        },
        "834321d10934449db30e2c072d32a48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca70b3fa2524a5c85fe302c8975c05e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7b95d9889844e6997e39181043be00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f99ea3a4bdc47a49b3f4ec4f549f89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8a35595d7d4662a91b6eb063542cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f08232af4f874ba68a99ffd402394549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6b63b1844c49359aa3b648e5123ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enxo7899/INM706-MachineTranslation/blob/main/INM706_Seq2Seq_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIPBm9a6fjn1",
        "outputId": "bc4bdf57-73e6-4fc3-fd38-f345f85a7622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/897.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m890.9/897.5 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.4)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.2.0-py2.py3-none-any.whl (281 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.2.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# Set the notebook name\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"INM706-Seq2Seq_Machine_Translation.ipynb\"\n",
        "\n",
        "# Login with the API KEY\n",
        "wandb.login(key=\"9ce954fd827fd8d839648cb3708ff788ad51bafa\")\n",
        "\n",
        "# Initialize wandb run\n",
        "wandb.init(project='Translator', name='English-Albanian')\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the dataset\n",
        "with open('GlobalVoices.en-sq.en', 'r', encoding='utf-8') as f:\n",
        "    en_sentences = f.readlines()\n",
        "with open('GlobalVoices.en-sq.sq', 'r', encoding='utf-8') as f:\n",
        "    sq_sentences = f.readlines()\n",
        "\n",
        "# Verify dataset loaded correctly\n",
        "print(f\"English sentences sample: {en_sentences[:5]}\")\n",
        "print(f\"Albanian sentences sample: {sq_sentences[:5]}\")\n",
        "print(f\"Total number of sentence pairs: {len(en_sentences)}\")\n",
        "\n",
        "# Use MarianTokenizer for tokenization\n",
        "tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-sq')\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, trg_sentences, tokenizer, max_length=128):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.trg_sentences = trg_sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_sentences[idx]\n",
        "        trg = self.trg_sentences[idx]\n",
        "\n",
        "        src_enc = self.tokenizer.encode_plus(\n",
        "            src,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        trg_enc = self.tokenizer.encode_plus(\n",
        "            trg,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'src': src_enc['input_ids'].squeeze(),\n",
        "            'src_mask': src_enc['attention_mask'].squeeze(),\n",
        "            'trg': trg_enc['input_ids'].squeeze(),\n",
        "            'trg_mask': trg_enc['attention_mask'].squeeze()\n",
        "        }\n",
        "\n",
        "# Create the dataset objects\n",
        "dataset = TranslationDataset(en_sentences, sq_sentences, tokenizer)\n",
        "\n",
        "# Split the dataset into train and validation sets (90% train, 10% validation)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Data preprocessing complete.\")\n",
        "\n",
        "# Define the Seq2Seq model components\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        hidden = hidden.unsqueeze(0).repeat(2, 1, 1)\n",
        "        cell = cell[-2:].contiguous()\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim * 3, hidden_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = torch.sum(self.v * energy, dim=2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM((hidden_dim * 2) + emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear((hidden_dim * 2) + hidden_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attention(hidden[-1], encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        input = trg[0,:]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
        "        return outputs\n",
        "\n",
        "# Model hyperparameters\n",
        "INPUT_DIM = tokenizer.vocab_size\n",
        "OUTPUT_DIM = tokenizer.vocab_size\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# Initialize wandb configuration\n",
        "wandb.config.update({\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 32,\n",
        "    \"encoder_embedding_dim\": ENC_EMB_DIM,\n",
        "    \"decoder_embedding_dim\": DEC_EMB_DIM,\n",
        "    \"hidden_dim\": HID_DIM,\n",
        "    \"num_layers\": N_LAYERS,\n",
        "    \"encoder_dropout\": ENC_DROPOUT,\n",
        "    \"decoder_dropout\": DEC_DROPOUT\n",
        "})\n",
        "\n",
        "# Initialize encoder, attention, decoder, and seq2seq model\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attn = Attention(HID_DIM).to(device)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn).to(device)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "TRG_PAD_IDX = tokenizer.pad_token_id\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch['src'].T.to(device)\n",
        "        trg = batch['trg'].T.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = output.argmax(1)\n",
        "        non_pad_elements = (trg != TRG_PAD_IDX).nonzero().squeeze()\n",
        "        correct = preds[non_pad_elements].eq(trg[non_pad_elements]).sum().item()\n",
        "        acc = correct / len(non_pad_elements)\n",
        "        epoch_acc += acc\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\"batch_loss\": loss.item(), \"batch_accuracy\": acc})\n",
        "\n",
        "        # Print some batches\n",
        "        if i % 10 == 0:\n",
        "            print(f'Batch {i} | Loss: {loss.item():.3f} | Accuracy: {acc:.3f}')\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch['src'].T.to(device)\n",
        "            trg = batch['trg'].T.to(device)\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = output.argmax(1)\n",
        "            non_pad_elements = (trg != TRG_PAD_IDX).nonzero().squeeze()\n",
        "            correct = preds[non_pad_elements].eq(trg[non_pad_elements]).sum().item()\n",
        "            acc = correct / len(non_pad_elements)\n",
        "            epoch_acc += acc\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "N_EPOCHS = wandb.config.epochs\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Train Acc: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} |  Val. Acc: {valid_acc:.3f}')\n",
        "\n",
        "    # Log epoch metrics to wandb\n",
        "    wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc,\n",
        "               \"valid_loss\": valid_loss, \"valid_accuracy\": valid_acc,\n",
        "               \"epoch\": epoch + 1, \"epoch_time_mins\": epoch_mins, \"epoch_time_secs\": epoch_secs})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16f491e58a494e2a964f8105539bcb1f",
            "665cb2fe4ee649b4ac501415bac89335",
            "06bed08f801e485a953b8d79f8d73768",
            "ab4d61ac86604f7d8c3cd509e54f9545",
            "d671449a50c0493c897896998e4b6438",
            "19dabbcad139492782623b7fa90cd7ee",
            "dba331c4867140deb8cbbcf5eda85b84",
            "83082077696c4b49ac47cb6a6230774a",
            "594a9117ddce4f469cfb13e74138b261",
            "88b1120d0a8843fc8eb14a1b47db5d1d",
            "9252e89556db454898b31170c756e602",
            "5bb6023ad7e64d7eae56a1ec7b1cca12",
            "98cbc35627104e3bab43a7fd0d941d96",
            "164ce3f036b74e389198a5540821dca4",
            "2085d37107d649a9a799f23bcce445d2",
            "24a39f272fca4cdcbad792a4747c3ed9",
            "08dc7d5f6943421e934e4b8e51cd7ac3",
            "5dcc1c91a710438497f8097a558d428b",
            "8852d0854a9946878ae2cb6ec0e75c67",
            "9231409402134d69956f5044c65ec163",
            "312cf306ad5441e0a05020846656e1d3",
            "72dedb0bdaf74a0c93efe79b873fe432",
            "c9653cd0864e4887b024018424fed75c",
            "2795d17c40f04980b8c0c4c5ca33d4ef",
            "6ef5cf6430b047e39f8f0e7f2f63193f",
            "d00c591ee60846a18fc689c6b4f976ec",
            "4328b57524cd45b8909f0ba5e1f4dcd6",
            "5451d7bd8bf1466e8d54fe2d47b56eb1",
            "fa3c9418be494e1fa8d709f26656d89a",
            "0207c319f05b423a87e0ef988e5621f7",
            "5d17c8c90d954b8e8f48f101b8f8360e",
            "680a19b174a2449bbc634f0e3965bf71",
            "cbddc0d652784b50a0228b50f74dbcd4",
            "3a682fbd83114de0948082510749024f",
            "2d45dbe9dfa8474c891dcede6dd4cf03",
            "d2634e2d1d0049c89c950df42ce1f0d7",
            "733d5334df13470aa722e0a002a99a0d",
            "7e4b277217ca41579fb2e32507c5c960",
            "97516e127d9d41da8da679b8b8e034a0",
            "8c056ec346da4824b54cd3bde01831cb",
            "5b8e5f5326f74cb79003a67a2342a771",
            "28b9bacc60134dd39355ba165e9e15da",
            "f098b7ac2cfe4b0a966c57136488e5af",
            "8d22846459b64798990cd58eac6a6a09",
            "49f7b6f4839f46a6af436170df544067",
            "6736f9ea51ca41f4935b30fd7f440834",
            "43b686666041420f8993c79cec8d251b",
            "64eac4a88c6a47bb95a11e60438530c3",
            "834321d10934449db30e2c072d32a48a",
            "6ca70b3fa2524a5c85fe302c8975c05e",
            "2e7b95d9889844e6997e39181043be00",
            "4f99ea3a4bdc47a49b3f4ec4f549f89b",
            "1f8a35595d7d4662a91b6eb063542cc4",
            "f08232af4f874ba68a99ffd402394549",
            "ee6b63b1844c49359aa3b648e5123ba6"
          ]
        },
        "id": "96o_pyEfnc9Y",
        "outputId": "37e89067-cdd9-4def-fa9a-ab70012c46b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find INM706-Seq2Seq_Machine_Translation.ipynb.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menxo7899\u001b[0m (\u001b[33mem-city\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240519_023603-8ostjw2o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/em-city/Translator/runs/8ostjw2o' target=\"_blank\">English-Albanian</a></strong> to <a href='https://wandb.ai/em-city/Translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/em-city/Translator' target=\"_blank\">https://wandb.ai/em-city/Translator</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/em-city/Translator/runs/8ostjw2o' target=\"_blank\">https://wandb.ai/em-city/Translator/runs/8ostjw2o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "English sentences sample: ['South Korea: North Korean Dictator, Kim Jong Il Is Dead · Global Voices\\n', 'Kim Jong Il, the North Korean dictator who ruled the hermit kingdom for the past three decades, has died at the age of 69.\\n', 'According to North Korean state television\\'s official report on Monday, Kim passed away from \"mental and physical strain\" during a train ride on December 17, 2011.\\n', 'The South Korean Twittersphere erupted with various responses.\\n', \"Although the death of one of the world's most notorious dictators is something people might welcome, most South Koreans have expressed concern about the instability his sudden death might bring to Korean peninsula.\\n\"]\n",
            "Albanian sentences sample: ['Kore: Vdes diktatori koreano-verior, Kim Jong Il\\n', 'Kim Jong Il, diktatori koreano-verior, i cili sundoi me mbretërinë e izoluar gjatë tre dekadave të kaluara, vdiq në moshën 69 vjeçare.\\n', 'Sipas lajmit zyrtar të emituar ditën e hënë në televizionin shtetëror koreano-verior, Kim ka ndërruar jetë si rezultat i \"lodhjes mendore dhe fizike\" gjatë një udhëtimit me tren, më 17 dhjetor të vitit 2011.\\n', 'Twittersfera koreano-jugore shpërtheu me reagime të ndryshme.\\n', 'Edhe pse vdekja e njërit prej diktatorëve më famëkeq botërorë është diçka që njerëzit mund ta mirëpresin, shumica e koreano-jugorëve kanë shprehur shqetësimin e tyre për destabilizimin e mundshëm të gadishullit korean për shkak të vdekjes së tij të papritur.\\n']\n",
            "Total number of sentence pairs: 5784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16f491e58a494e2a964f8105539bcb1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/805k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bb6023ad7e64d7eae56a1ec7b1cca12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/822k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9653cd0864e4887b024018424fed75c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a682fbd83114de0948082510749024f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49f7b6f4839f46a6af436170df544067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete.\n",
            "Batch 0 | Loss: 11.030 | Accuracy: 0.000\n",
            "Batch 10 | Loss: 6.200 | Accuracy: 0.077\n",
            "Batch 20 | Loss: 6.034 | Accuracy: 0.084\n",
            "Batch 30 | Loss: 5.932 | Accuracy: 0.082\n",
            "Batch 40 | Loss: 6.256 | Accuracy: 0.063\n",
            "Batch 50 | Loss: 5.770 | Accuracy: 0.095\n",
            "Batch 60 | Loss: 5.713 | Accuracy: 0.093\n",
            "Batch 70 | Loss: 5.755 | Accuracy: 0.098\n",
            "Batch 80 | Loss: 5.541 | Accuracy: 0.114\n",
            "Batch 90 | Loss: 5.758 | Accuracy: 0.102\n",
            "Batch 100 | Loss: 5.529 | Accuracy: 0.112\n",
            "Batch 110 | Loss: 5.575 | Accuracy: 0.113\n",
            "Batch 120 | Loss: 5.692 | Accuracy: 0.090\n",
            "Batch 130 | Loss: 5.780 | Accuracy: 0.101\n",
            "Batch 140 | Loss: 5.778 | Accuracy: 0.083\n",
            "Batch 150 | Loss: 5.531 | Accuracy: 0.121\n",
            "Batch 160 | Loss: 5.422 | Accuracy: 0.111\n",
            "Epoch: 01 | Time: 3m 23s\n",
            "\tTrain Loss: 5.896 | Train PPL: 363.687 | Train Acc: 0.091\n",
            "\t Val. Loss: 5.980 |  Val. PPL: 395.319 |  Val. Acc: 0.069\n",
            "Batch 0 | Loss: 5.687 | Accuracy: 0.101\n",
            "Batch 10 | Loss: 5.707 | Accuracy: 0.102\n",
            "Batch 20 | Loss: 5.445 | Accuracy: 0.120\n",
            "Batch 30 | Loss: 5.460 | Accuracy: 0.108\n",
            "Batch 40 | Loss: 5.449 | Accuracy: 0.102\n",
            "Batch 50 | Loss: 5.454 | Accuracy: 0.110\n",
            "Batch 60 | Loss: 5.458 | Accuracy: 0.125\n",
            "Batch 70 | Loss: 5.346 | Accuracy: 0.112\n",
            "Batch 80 | Loss: 5.297 | Accuracy: 0.135\n",
            "Batch 90 | Loss: 5.326 | Accuracy: 0.117\n",
            "Batch 100 | Loss: 5.277 | Accuracy: 0.119\n",
            "Batch 110 | Loss: 5.342 | Accuracy: 0.118\n",
            "Batch 120 | Loss: 5.456 | Accuracy: 0.102\n",
            "Batch 130 | Loss: 5.383 | Accuracy: 0.112\n",
            "Batch 140 | Loss: 5.229 | Accuracy: 0.124\n",
            "Batch 150 | Loss: 5.592 | Accuracy: 0.120\n",
            "Batch 160 | Loss: 5.588 | Accuracy: 0.124\n",
            "Epoch: 02 | Time: 3m 22s\n",
            "\tTrain Loss: 5.429 | Train PPL: 227.860 | Train Acc: 0.117\n",
            "\t Val. Loss: 5.936 |  Val. PPL: 378.418 |  Val. Acc: 0.059\n",
            "Batch 0 | Loss: 5.126 | Accuracy: 0.149\n",
            "Batch 10 | Loss: 5.151 | Accuracy: 0.130\n",
            "Batch 20 | Loss: 5.263 | Accuracy: 0.143\n",
            "Batch 30 | Loss: 5.309 | Accuracy: 0.119\n",
            "Batch 40 | Loss: 5.286 | Accuracy: 0.131\n",
            "Batch 50 | Loss: 5.105 | Accuracy: 0.134\n",
            "Batch 60 | Loss: 5.336 | Accuracy: 0.138\n",
            "Batch 70 | Loss: 5.277 | Accuracy: 0.128\n",
            "Batch 80 | Loss: 5.300 | Accuracy: 0.128\n",
            "Batch 90 | Loss: 5.248 | Accuracy: 0.126\n",
            "Batch 100 | Loss: 5.270 | Accuracy: 0.130\n",
            "Batch 110 | Loss: 5.301 | Accuracy: 0.139\n",
            "Batch 120 | Loss: 5.082 | Accuracy: 0.145\n",
            "Batch 130 | Loss: 5.283 | Accuracy: 0.115\n",
            "Batch 140 | Loss: 5.255 | Accuracy: 0.136\n",
            "Batch 150 | Loss: 5.278 | Accuracy: 0.128\n",
            "Batch 160 | Loss: 5.447 | Accuracy: 0.124\n",
            "Epoch: 03 | Time: 3m 22s\n",
            "\tTrain Loss: 5.251 | Train PPL: 190.728 | Train Acc: 0.129\n",
            "\t Val. Loss: 5.862 |  Val. PPL: 351.498 |  Val. Acc: 0.074\n",
            "Batch 0 | Loss: 5.164 | Accuracy: 0.127\n",
            "Batch 10 | Loss: 5.029 | Accuracy: 0.140\n",
            "Batch 20 | Loss: 5.046 | Accuracy: 0.142\n",
            "Batch 30 | Loss: 5.001 | Accuracy: 0.143\n",
            "Batch 40 | Loss: 5.296 | Accuracy: 0.126\n",
            "Batch 50 | Loss: 5.091 | Accuracy: 0.134\n",
            "Batch 60 | Loss: 5.121 | Accuracy: 0.137\n",
            "Batch 70 | Loss: 5.064 | Accuracy: 0.141\n",
            "Batch 80 | Loss: 5.013 | Accuracy: 0.156\n",
            "Batch 90 | Loss: 5.037 | Accuracy: 0.165\n",
            "Batch 100 | Loss: 5.163 | Accuracy: 0.133\n",
            "Batch 110 | Loss: 5.293 | Accuracy: 0.116\n",
            "Batch 120 | Loss: 5.068 | Accuracy: 0.134\n",
            "Batch 130 | Loss: 5.148 | Accuracy: 0.124\n",
            "Batch 140 | Loss: 5.402 | Accuracy: 0.113\n",
            "Batch 150 | Loss: 5.186 | Accuracy: 0.131\n",
            "Batch 160 | Loss: 5.219 | Accuracy: 0.143\n",
            "Epoch: 04 | Time: 3m 22s\n",
            "\tTrain Loss: 5.143 | Train PPL: 171.151 | Train Acc: 0.137\n",
            "\t Val. Loss: 5.842 |  Val. PPL: 344.406 |  Val. Acc: 0.076\n",
            "Batch 0 | Loss: 5.474 | Accuracy: 0.112\n",
            "Batch 10 | Loss: 4.977 | Accuracy: 0.144\n",
            "Batch 20 | Loss: 4.953 | Accuracy: 0.148\n",
            "Batch 30 | Loss: 5.039 | Accuracy: 0.151\n",
            "Batch 40 | Loss: 5.252 | Accuracy: 0.138\n",
            "Batch 50 | Loss: 4.996 | Accuracy: 0.152\n",
            "Batch 60 | Loss: 4.921 | Accuracy: 0.155\n",
            "Batch 70 | Loss: 5.294 | Accuracy: 0.132\n",
            "Batch 80 | Loss: 4.940 | Accuracy: 0.165\n",
            "Batch 90 | Loss: 4.984 | Accuracy: 0.155\n",
            "Batch 100 | Loss: 5.204 | Accuracy: 0.124\n",
            "Batch 110 | Loss: 5.047 | Accuracy: 0.153\n",
            "Batch 120 | Loss: 4.992 | Accuracy: 0.143\n",
            "Batch 130 | Loss: 4.982 | Accuracy: 0.153\n",
            "Batch 140 | Loss: 5.045 | Accuracy: 0.140\n",
            "Batch 150 | Loss: 4.852 | Accuracy: 0.153\n",
            "Batch 160 | Loss: 4.963 | Accuracy: 0.142\n",
            "Epoch: 05 | Time: 3m 22s\n",
            "\tTrain Loss: 5.064 | Train PPL: 158.279 | Train Acc: 0.144\n",
            "\t Val. Loss: 5.860 |  Val. PPL: 350.555 |  Val. Acc: 0.068\n",
            "Batch 0 | Loss: 5.150 | Accuracy: 0.136\n",
            "Batch 10 | Loss: 4.951 | Accuracy: 0.155\n",
            "Batch 20 | Loss: 5.026 | Accuracy: 0.130\n",
            "Batch 30 | Loss: 5.015 | Accuracy: 0.159\n",
            "Batch 40 | Loss: 5.000 | Accuracy: 0.156\n",
            "Batch 50 | Loss: 4.812 | Accuracy: 0.148\n",
            "Batch 60 | Loss: 5.009 | Accuracy: 0.138\n",
            "Batch 70 | Loss: 4.777 | Accuracy: 0.166\n",
            "Batch 80 | Loss: 4.971 | Accuracy: 0.147\n",
            "Batch 90 | Loss: 5.023 | Accuracy: 0.124\n",
            "Batch 100 | Loss: 4.987 | Accuracy: 0.141\n",
            "Batch 110 | Loss: 4.877 | Accuracy: 0.147\n",
            "Batch 120 | Loss: 4.932 | Accuracy: 0.152\n",
            "Batch 130 | Loss: 4.921 | Accuracy: 0.158\n",
            "Batch 140 | Loss: 4.880 | Accuracy: 0.156\n",
            "Batch 150 | Loss: 4.745 | Accuracy: 0.171\n",
            "Batch 160 | Loss: 4.816 | Accuracy: 0.159\n",
            "Epoch: 06 | Time: 3m 22s\n",
            "\tTrain Loss: 4.989 | Train PPL: 146.825 | Train Acc: 0.149\n",
            "\t Val. Loss: 5.845 |  Val. PPL: 345.469 |  Val. Acc: 0.075\n",
            "Batch 0 | Loss: 4.731 | Accuracy: 0.169\n",
            "Batch 10 | Loss: 4.813 | Accuracy: 0.167\n",
            "Batch 20 | Loss: 4.911 | Accuracy: 0.159\n",
            "Batch 30 | Loss: 4.684 | Accuracy: 0.186\n",
            "Batch 40 | Loss: 4.760 | Accuracy: 0.162\n",
            "Batch 50 | Loss: 5.001 | Accuracy: 0.135\n",
            "Batch 60 | Loss: 4.966 | Accuracy: 0.163\n",
            "Batch 70 | Loss: 4.828 | Accuracy: 0.175\n",
            "Batch 80 | Loss: 4.682 | Accuracy: 0.168\n",
            "Batch 90 | Loss: 4.893 | Accuracy: 0.166\n",
            "Batch 100 | Loss: 4.736 | Accuracy: 0.173\n",
            "Batch 110 | Loss: 4.817 | Accuracy: 0.167\n",
            "Batch 120 | Loss: 4.863 | Accuracy: 0.160\n",
            "Batch 130 | Loss: 4.806 | Accuracy: 0.163\n",
            "Batch 140 | Loss: 4.931 | Accuracy: 0.168\n",
            "Batch 150 | Loss: 4.931 | Accuracy: 0.155\n",
            "Batch 160 | Loss: 5.085 | Accuracy: 0.140\n",
            "Epoch: 07 | Time: 3m 22s\n",
            "\tTrain Loss: 4.899 | Train PPL: 134.211 | Train Acc: 0.156\n",
            "\t Val. Loss: 5.795 |  Val. PPL: 328.755 |  Val. Acc: 0.082\n",
            "Batch 0 | Loss: 4.743 | Accuracy: 0.157\n",
            "Batch 10 | Loss: 4.877 | Accuracy: 0.138\n",
            "Batch 20 | Loss: 4.825 | Accuracy: 0.145\n",
            "Batch 30 | Loss: 4.916 | Accuracy: 0.151\n",
            "Batch 40 | Loss: 4.761 | Accuracy: 0.177\n",
            "Batch 50 | Loss: 4.929 | Accuracy: 0.146\n",
            "Batch 60 | Loss: 4.767 | Accuracy: 0.170\n",
            "Batch 70 | Loss: 4.903 | Accuracy: 0.150\n",
            "Batch 80 | Loss: 4.709 | Accuracy: 0.168\n",
            "Batch 90 | Loss: 4.920 | Accuracy: 0.166\n",
            "Batch 100 | Loss: 4.907 | Accuracy: 0.160\n",
            "Batch 110 | Loss: 4.892 | Accuracy: 0.163\n",
            "Batch 120 | Loss: 4.871 | Accuracy: 0.156\n",
            "Batch 130 | Loss: 4.958 | Accuracy: 0.145\n",
            "Batch 140 | Loss: 5.044 | Accuracy: 0.147\n",
            "Batch 150 | Loss: 5.197 | Accuracy: 0.130\n",
            "Batch 160 | Loss: 4.858 | Accuracy: 0.163\n",
            "Epoch: 08 | Time: 3m 22s\n",
            "\tTrain Loss: 4.836 | Train PPL: 125.997 | Train Acc: 0.161\n",
            "\t Val. Loss: 5.797 |  Val. PPL: 329.150 |  Val. Acc: 0.081\n",
            "Batch 0 | Loss: 4.767 | Accuracy: 0.159\n",
            "Batch 10 | Loss: 4.615 | Accuracy: 0.174\n",
            "Batch 20 | Loss: 4.777 | Accuracy: 0.159\n",
            "Batch 30 | Loss: 4.784 | Accuracy: 0.158\n",
            "Batch 40 | Loss: 4.661 | Accuracy: 0.167\n",
            "Batch 50 | Loss: 4.854 | Accuracy: 0.169\n",
            "Batch 60 | Loss: 4.672 | Accuracy: 0.177\n",
            "Batch 70 | Loss: 4.741 | Accuracy: 0.164\n",
            "Batch 80 | Loss: 4.458 | Accuracy: 0.179\n",
            "Batch 90 | Loss: 4.496 | Accuracy: 0.194\n",
            "Batch 100 | Loss: 4.642 | Accuracy: 0.193\n",
            "Batch 110 | Loss: 4.648 | Accuracy: 0.161\n",
            "Batch 120 | Loss: 4.854 | Accuracy: 0.167\n",
            "Batch 130 | Loss: 4.798 | Accuracy: 0.161\n",
            "Batch 140 | Loss: 4.583 | Accuracy: 0.186\n",
            "Batch 150 | Loss: 4.729 | Accuracy: 0.181\n",
            "Batch 160 | Loss: 4.685 | Accuracy: 0.171\n",
            "Epoch: 09 | Time: 3m 22s\n",
            "\tTrain Loss: 4.764 | Train PPL: 117.168 | Train Acc: 0.166\n",
            "\t Val. Loss: 5.777 |  Val. PPL: 322.660 |  Val. Acc: 0.080\n",
            "Batch 0 | Loss: 4.507 | Accuracy: 0.191\n",
            "Batch 10 | Loss: 4.813 | Accuracy: 0.160\n",
            "Batch 20 | Loss: 4.688 | Accuracy: 0.166\n",
            "Batch 30 | Loss: 4.582 | Accuracy: 0.172\n",
            "Batch 40 | Loss: 4.605 | Accuracy: 0.184\n",
            "Batch 50 | Loss: 4.749 | Accuracy: 0.164\n",
            "Batch 60 | Loss: 4.796 | Accuracy: 0.159\n",
            "Batch 70 | Loss: 4.555 | Accuracy: 0.192\n",
            "Batch 80 | Loss: 4.670 | Accuracy: 0.178\n",
            "Batch 90 | Loss: 4.754 | Accuracy: 0.184\n",
            "Batch 100 | Loss: 4.516 | Accuracy: 0.184\n",
            "Batch 110 | Loss: 5.022 | Accuracy: 0.152\n",
            "Batch 120 | Loss: 4.837 | Accuracy: 0.151\n",
            "Batch 130 | Loss: 4.839 | Accuracy: 0.159\n",
            "Batch 140 | Loss: 4.827 | Accuracy: 0.160\n",
            "Batch 150 | Loss: 4.630 | Accuracy: 0.176\n",
            "Batch 160 | Loss: 4.763 | Accuracy: 0.157\n",
            "Epoch: 10 | Time: 3m 23s\n",
            "\tTrain Loss: 4.706 | Train PPL: 110.653 | Train Acc: 0.172\n",
            "\t Val. Loss: 5.770 |  Val. PPL: 320.525 |  Val. Acc: 0.085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import MarianTokenizer, MarianMTModel\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import wandb\n",
        "import os\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "# Set the notebook name\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"INM706-Seq2Seq_Machine_Translation.ipynb\"\n",
        "\n",
        "# Login with the API KEY\n",
        "wandb.login(key=\"9ce954fd827fd8d839648cb3708ff788ad51bafa\")\n",
        "\n",
        "# Initialize wandb run\n",
        "wandb.init(project='Translator', name='English-Albanian')\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the dataset\n",
        "with open('GlobalVoices.en-sq.en', 'r', encoding='utf-8') as f:\n",
        "    en_sentences = f.readlines()\n",
        "with open('GlobalVoices.en-sq.sq', 'r', encoding='utf-8') as f:\n",
        "    sq_sentences = f.readlines()\n",
        "\n",
        "# Verify dataset loaded correctly\n",
        "print(f\"English sentences sample: {en_sentences[:5]}\")\n",
        "print(f\"Albanian sentences sample: {sq_sentences[:5]}\")\n",
        "print(f\"Total number of sentence pairs: {len(en_sentences)}\")\n",
        "\n",
        "# Use MarianTokenizer for tokenization\n",
        "tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-sq')\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, trg_sentences, tokenizer, max_length=128):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.trg_sentences = trg_sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_sentences[idx]\n",
        "        trg = self.trg_sentences[idx]\n",
        "\n",
        "        src_enc = self.tokenizer.encode_plus(\n",
        "            src,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        trg_enc = self.tokenizer.encode_plus(\n",
        "            trg,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'src': src_enc['input_ids'].squeeze(),\n",
        "            'src_mask': src_enc['attention_mask'].squeeze(),\n",
        "            'trg': trg_enc['input_ids'].squeeze(),\n",
        "            'trg_mask': trg_enc['attention_mask'].squeeze()\n",
        "        }\n",
        "\n",
        "# Create the dataset objects\n",
        "dataset = TranslationDataset(en_sentences, sq_sentences, tokenizer)\n",
        "\n",
        "# Split the dataset into train and validation sets (90% train, 10% validation)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Data preprocessing complete.\")\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "\n",
        "        hidden = hidden.unsqueeze(0).repeat(2, 1, 1)\n",
        "        cell = cell[-2:].contiguous()\n",
        "\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim * 3, hidden_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = torch.sum(self.v * energy, dim=2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM((hidden_dim * 2) + emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear((hidden_dim * 2) + hidden_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attention(hidden[-1], encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Model hyperparameters\n",
        "INPUT_DIM = tokenizer.vocab_size\n",
        "OUTPUT_DIM = tokenizer.vocab_size\n",
        "ENC_EMB_DIM = 512\n",
        "DEC_EMB_DIM = 512\n",
        "HID_DIM = 1024\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "\n",
        "wandb.config.update({\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"epochs\": 30,\n",
        "    \"batch_size\": 64,\n",
        "    \"encoder_embedding_dim\": ENC_EMB_DIM,\n",
        "    \"decoder_embedding_dim\": DEC_EMB_DIM,\n",
        "    \"hidden_dim\": HID_DIM,\n",
        "    \"num_layers\": N_LAYERS,\n",
        "    \"encoder_dropout\": ENC_DROPOUT,\n",
        "    \"decoder_dropout\": DEC_DROPOUT\n",
        "})\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n",
        "attn = Attention(HID_DIM).to(device)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn).to(device)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "TRG_PAD_IDX = tokenizer.pad_token_id\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip, accum_steps=2):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch['src'].T.to(device)\n",
        "        trg = batch['trg'].T.to(device)\n",
        "\n",
        "        with autocast():\n",
        "            output = model(src, trg)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "            loss = criterion(output, trg) / accum_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % accum_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item() * accum_steps\n",
        "\n",
        "        preds = output.argmax(1)\n",
        "        non_pad_elements = (trg != TRG_PAD_IDX).nonzero().squeeze()\n",
        "        correct = preds[non_pad_elements].eq(trg[non_pad_elements]).sum().item()\n",
        "        acc = correct / len(non_pad_elements)\n",
        "        epoch_acc += acc\n",
        "\n",
        "        wandb.log({\"batch_loss\": loss.item() * accum_steps, \"batch_accuracy\": acc})\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f'Batch {i} | Loss: {loss.item() * accum_steps:.3f} | Accuracy: {acc:.3f}')\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    all_preds = []\n",
        "    all_trgs = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch['src'].T.to(device)\n",
        "            trg = batch['trg'].T.to(device)\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            preds = output.argmax(1)\n",
        "            non_pad_elements = (trg != TRG_PAD_IDX).nonzero().squeeze()\n",
        "            correct = preds[non_pad_elements].eq(trg[non_pad_elements]).sum().item()\n",
        "            acc = correct / len(non_pad_elements)\n",
        "            epoch_acc += acc\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_trgs.append(trg.cpu().numpy())\n",
        "\n",
        "    all_preds = [list(map(str, sent)) for sent in all_preds]\n",
        "    all_trgs = [list(map(str, sent)) for sent in all_trgs]\n",
        "    bleu = bleu_score(all_preds, [[trg] for trg in all_trgs])\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), bleu\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "if not os.path.exists('checkpoints'):\n",
        "    os.makedirs('checkpoints')\n",
        "\n",
        "N_EPOCHS = wandb.config.epochs\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss, valid_acc, bleu = evaluate(model, val_loader, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'checkpoints/seq2seq_model_epoch{epoch+1}.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Train Acc: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} |  Val. Acc: {valid_acc:.3f} |  Val. BLEU: {bleu:.3f}')\n",
        "\n",
        "    wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc,\n",
        "               \"valid_loss\": valid_loss, \"valid_accuracy\": valid_acc, \"valid_bleu\": bleu,\n",
        "               \"epoch\": epoch + 1, \"epoch_time_mins\": epoch_mins, \"epoch_time_secs\": epoch_secs})\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "98fa242aeed44c60a50baacea965c18b"
          ]
        },
        "id": "_QxtWEgf0mzy",
        "outputId": "b263198a-bd24-49d1-9d83-6cbbb927dbff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240519_112651-15ja72to</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/em-city/Translator/runs/15ja72to' target=\"_blank\">English-Albanian</a></strong> to <a href='https://wandb.ai/em-city/Translator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/em-city/Translator' target=\"_blank\">https://wandb.ai/em-city/Translator</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/em-city/Translator/runs/15ja72to' target=\"_blank\">https://wandb.ai/em-city/Translator/runs/15ja72to</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "English sentences sample: ['South Korea: North Korean Dictator, Kim Jong Il Is Dead · Global Voices\\n', 'Kim Jong Il, the North Korean dictator who ruled the hermit kingdom for the past three decades, has died at the age of 69.\\n', 'According to North Korean state television\\'s official report on Monday, Kim passed away from \"mental and physical strain\" during a train ride on December 17, 2011.\\n', 'The South Korean Twittersphere erupted with various responses.\\n', \"Although the death of one of the world's most notorious dictators is something people might welcome, most South Koreans have expressed concern about the instability his sudden death might bring to Korean peninsula.\\n\"]\n",
            "Albanian sentences sample: ['Kore: Vdes diktatori koreano-verior, Kim Jong Il\\n', 'Kim Jong Il, diktatori koreano-verior, i cili sundoi me mbretërinë e izoluar gjatë tre dekadave të kaluara, vdiq në moshën 69 vjeçare.\\n', 'Sipas lajmit zyrtar të emituar ditën e hënë në televizionin shtetëror koreano-verior, Kim ka ndërruar jetë si rezultat i \"lodhjes mendore dhe fizike\" gjatë një udhëtimit me tren, më 17 dhjetor të vitit 2011.\\n', 'Twittersfera koreano-jugore shpërtheu me reagime të ndryshme.\\n', 'Edhe pse vdekja e njërit prej diktatorëve më famëkeq botërorë është diçka që njerëzit mund ta mirëpresin, shumica e koreano-jugorëve kanë shprehur shqetësimin e tyre për destabilizimin e mundshëm të gadishullit korean për shkak të vdekjes së tij të papritur.\\n']\n",
            "Total number of sentence pairs: 5784\n",
            "Data preprocessing complete.\n",
            "Batch 0 | Loss: 11.013 | Accuracy: 0.000\n",
            "Batch 10 | Loss: 10.021 | Accuracy: 0.059\n",
            "Batch 20 | Loss: 7.995 | Accuracy: 0.056\n",
            "Batch 30 | Loss: 7.450 | Accuracy: 0.059\n",
            "Batch 40 | Loss: 7.144 | Accuracy: 0.053\n",
            "Batch 50 | Loss: 6.943 | Accuracy: 0.049\n",
            "Batch 60 | Loss: 6.603 | Accuracy: 0.078\n",
            "Batch 70 | Loss: 6.463 | Accuracy: 0.057\n",
            "Batch 80 | Loss: 6.081 | Accuracy: 0.112\n",
            "Batch 90 | Loss: 5.837 | Accuracy: 0.104\n",
            "Batch 100 | Loss: 5.980 | Accuracy: 0.089\n",
            "Batch 110 | Loss: 5.904 | Accuracy: 0.099\n",
            "Batch 120 | Loss: 5.931 | Accuracy: 0.093\n",
            "Batch 130 | Loss: 5.585 | Accuracy: 0.114\n",
            "Batch 140 | Loss: 5.768 | Accuracy: 0.104\n",
            "Batch 150 | Loss: 5.753 | Accuracy: 0.113\n",
            "Batch 160 | Loss: 5.414 | Accuracy: 0.128\n",
            "Batch 170 | Loss: 5.978 | Accuracy: 0.102\n",
            "Batch 180 | Loss: 5.745 | Accuracy: 0.104\n",
            "Batch 190 | Loss: 5.881 | Accuracy: 0.103\n",
            "Batch 200 | Loss: 5.475 | Accuracy: 0.115\n",
            "Batch 210 | Loss: 5.737 | Accuracy: 0.095\n",
            "Batch 220 | Loss: 5.895 | Accuracy: 0.093\n",
            "Batch 230 | Loss: 5.834 | Accuracy: 0.095\n",
            "Batch 240 | Loss: 5.574 | Accuracy: 0.106\n",
            "Batch 250 | Loss: 5.602 | Accuracy: 0.115\n",
            "Batch 260 | Loss: 5.394 | Accuracy: 0.125\n",
            "Batch 270 | Loss: 5.363 | Accuracy: 0.137\n",
            "Batch 280 | Loss: 5.950 | Accuracy: 0.087\n",
            "Batch 290 | Loss: 5.616 | Accuracy: 0.107\n",
            "Batch 300 | Loss: 5.672 | Accuracy: 0.117\n",
            "Batch 310 | Loss: 5.581 | Accuracy: 0.118\n",
            "Batch 320 | Loss: 5.320 | Accuracy: 0.143\n",
            "Epoch: 01 | Time: 5m 7s\n",
            "\tTrain Loss: 6.179 | Train PPL: 482.444 | Train Acc: 0.097\n",
            "\t Val. Loss: 6.048 |  Val. PPL: 423.416 |  Val. Acc: 0.060 |  Val. BLEU: 0.002\n",
            "Batch 0 | Loss: 5.223 | Accuracy: 0.128\n",
            "Batch 10 | Loss: 5.485 | Accuracy: 0.141\n",
            "Batch 20 | Loss: 5.577 | Accuracy: 0.114\n",
            "Batch 30 | Loss: 5.159 | Accuracy: 0.143\n",
            "Batch 40 | Loss: 5.715 | Accuracy: 0.099\n",
            "Batch 50 | Loss: 5.302 | Accuracy: 0.136\n",
            "Batch 60 | Loss: 5.659 | Accuracy: 0.118\n",
            "Batch 70 | Loss: 5.268 | Accuracy: 0.162\n",
            "Batch 80 | Loss: 5.495 | Accuracy: 0.128\n",
            "Batch 90 | Loss: 5.399 | Accuracy: 0.127\n",
            "Batch 100 | Loss: 5.542 | Accuracy: 0.120\n",
            "Batch 110 | Loss: 5.495 | Accuracy: 0.120\n",
            "Batch 120 | Loss: 5.410 | Accuracy: 0.122\n",
            "Batch 130 | Loss: 5.563 | Accuracy: 0.099\n",
            "Batch 140 | Loss: 5.311 | Accuracy: 0.132\n",
            "Batch 150 | Loss: 5.471 | Accuracy: 0.104\n",
            "Batch 160 | Loss: 5.631 | Accuracy: 0.100\n",
            "Batch 170 | Loss: 5.148 | Accuracy: 0.151\n",
            "Batch 180 | Loss: 5.364 | Accuracy: 0.121\n",
            "Batch 190 | Loss: 5.493 | Accuracy: 0.124\n",
            "Batch 200 | Loss: 5.478 | Accuracy: 0.122\n",
            "Batch 210 | Loss: 5.439 | Accuracy: 0.120\n",
            "Batch 220 | Loss: 5.281 | Accuracy: 0.137\n",
            "Batch 230 | Loss: 5.350 | Accuracy: 0.114\n",
            "Batch 240 | Loss: 5.492 | Accuracy: 0.127\n",
            "Batch 250 | Loss: 5.332 | Accuracy: 0.144\n",
            "Batch 260 | Loss: 5.360 | Accuracy: 0.129\n",
            "Batch 270 | Loss: 5.680 | Accuracy: 0.115\n",
            "Batch 280 | Loss: 5.371 | Accuracy: 0.107\n",
            "Batch 290 | Loss: 5.163 | Accuracy: 0.147\n",
            "Batch 300 | Loss: 5.524 | Accuracy: 0.116\n",
            "Batch 310 | Loss: 5.142 | Accuracy: 0.163\n",
            "Batch 320 | Loss: 5.679 | Accuracy: 0.106\n",
            "Epoch: 02 | Time: 5m 7s\n",
            "\tTrain Loss: 5.445 | Train PPL: 231.640 | Train Acc: 0.122\n",
            "\t Val. Loss: 6.054 |  Val. PPL: 425.920 |  Val. Acc: 0.053 |  Val. BLEU: 0.003\n",
            "Batch 0 | Loss: 5.731 | Accuracy: 0.106\n",
            "Batch 10 | Loss: 5.376 | Accuracy: 0.145\n",
            "Batch 20 | Loss: 5.202 | Accuracy: 0.125\n",
            "Batch 30 | Loss: 5.273 | Accuracy: 0.130\n",
            "Batch 40 | Loss: 5.277 | Accuracy: 0.146\n",
            "Batch 50 | Loss: 5.462 | Accuracy: 0.132\n",
            "Batch 60 | Loss: 5.331 | Accuracy: 0.137\n",
            "Batch 70 | Loss: 5.173 | Accuracy: 0.147\n",
            "Batch 80 | Loss: 5.346 | Accuracy: 0.128\n",
            "Batch 90 | Loss: 5.015 | Accuracy: 0.156\n",
            "Batch 100 | Loss: 5.402 | Accuracy: 0.122\n",
            "Batch 110 | Loss: 5.519 | Accuracy: 0.100\n",
            "Batch 120 | Loss: 5.265 | Accuracy: 0.122\n",
            "Batch 130 | Loss: 5.384 | Accuracy: 0.124\n",
            "Batch 140 | Loss: 5.419 | Accuracy: 0.122\n",
            "Batch 150 | Loss: 5.241 | Accuracy: 0.164\n",
            "Batch 160 | Loss: 4.955 | Accuracy: 0.176\n",
            "Batch 170 | Loss: 5.166 | Accuracy: 0.154\n",
            "Batch 180 | Loss: 5.366 | Accuracy: 0.117\n",
            "Batch 190 | Loss: 5.810 | Accuracy: 0.094\n",
            "Batch 200 | Loss: 5.457 | Accuracy: 0.120\n",
            "Batch 210 | Loss: 5.299 | Accuracy: 0.126\n",
            "Batch 220 | Loss: 5.358 | Accuracy: 0.128\n",
            "Batch 230 | Loss: 5.563 | Accuracy: 0.110\n",
            "Batch 240 | Loss: 5.258 | Accuracy: 0.126\n",
            "Batch 250 | Loss: 5.520 | Accuracy: 0.105\n",
            "Batch 260 | Loss: 5.469 | Accuracy: 0.128\n",
            "Batch 270 | Loss: 5.583 | Accuracy: 0.113\n",
            "Batch 280 | Loss: 5.291 | Accuracy: 0.116\n",
            "Batch 290 | Loss: 5.043 | Accuracy: 0.140\n",
            "Batch 300 | Loss: 5.163 | Accuracy: 0.135\n",
            "Batch 310 | Loss: 5.080 | Accuracy: 0.147\n",
            "Batch 320 | Loss: 5.086 | Accuracy: 0.142\n",
            "Epoch: 03 | Time: 5m 7s\n",
            "\tTrain Loss: 5.320 | Train PPL: 204.318 | Train Acc: 0.129\n",
            "\t Val. Loss: 6.004 |  Val. PPL: 405.184 |  Val. Acc: 0.068 |  Val. BLEU: 0.002\n",
            "Batch 0 | Loss: 5.383 | Accuracy: 0.113\n",
            "Batch 10 | Loss: 5.541 | Accuracy: 0.115\n",
            "Batch 20 | Loss: 5.394 | Accuracy: 0.130\n",
            "Batch 30 | Loss: 5.003 | Accuracy: 0.137\n",
            "Batch 40 | Loss: 5.144 | Accuracy: 0.140\n",
            "Batch 50 | Loss: 5.443 | Accuracy: 0.117\n",
            "Batch 60 | Loss: 5.330 | Accuracy: 0.139\n",
            "Batch 70 | Loss: 5.069 | Accuracy: 0.132\n",
            "Batch 80 | Loss: 5.284 | Accuracy: 0.152\n",
            "Batch 90 | Loss: 5.412 | Accuracy: 0.117\n",
            "Batch 100 | Loss: 5.394 | Accuracy: 0.109\n",
            "Batch 110 | Loss: 5.390 | Accuracy: 0.122\n",
            "Batch 120 | Loss: 5.179 | Accuracy: 0.156\n",
            "Batch 130 | Loss: 5.023 | Accuracy: 0.150\n",
            "Batch 140 | Loss: 5.487 | Accuracy: 0.097\n",
            "Batch 150 | Loss: 5.192 | Accuracy: 0.132\n",
            "Batch 160 | Loss: 5.221 | Accuracy: 0.129\n",
            "Batch 170 | Loss: 5.343 | Accuracy: 0.125\n",
            "Batch 180 | Loss: 5.467 | Accuracy: 0.118\n",
            "Batch 190 | Loss: 5.510 | Accuracy: 0.103\n",
            "Batch 200 | Loss: 5.261 | Accuracy: 0.134\n",
            "Batch 210 | Loss: 5.097 | Accuracy: 0.164\n",
            "Batch 220 | Loss: 5.397 | Accuracy: 0.129\n",
            "Batch 230 | Loss: 5.117 | Accuracy: 0.150\n",
            "Batch 240 | Loss: 5.537 | Accuracy: 0.114\n",
            "Batch 250 | Loss: 5.257 | Accuracy: 0.137\n",
            "Batch 260 | Loss: 5.195 | Accuracy: 0.139\n",
            "Batch 270 | Loss: 5.363 | Accuracy: 0.132\n",
            "Batch 280 | Loss: 5.212 | Accuracy: 0.139\n",
            "Batch 290 | Loss: 5.222 | Accuracy: 0.130\n",
            "Batch 300 | Loss: 5.514 | Accuracy: 0.113\n",
            "Batch 310 | Loss: 5.146 | Accuracy: 0.141\n",
            "Batch 320 | Loss: 5.172 | Accuracy: 0.125\n",
            "Epoch: 04 | Time: 5m 7s\n",
            "\tTrain Loss: 5.237 | Train PPL: 188.064 | Train Acc: 0.134\n",
            "\t Val. Loss: 6.006 |  Val. PPL: 405.793 |  Val. Acc: 0.060 |  Val. BLEU: 0.002\n",
            "Batch 0 | Loss: 5.206 | Accuracy: 0.139\n",
            "Batch 10 | Loss: 5.057 | Accuracy: 0.131\n",
            "Batch 20 | Loss: 5.302 | Accuracy: 0.131\n",
            "Batch 30 | Loss: 5.375 | Accuracy: 0.125\n",
            "Batch 40 | Loss: 4.922 | Accuracy: 0.164\n",
            "Batch 50 | Loss: 5.104 | Accuracy: 0.129\n",
            "Batch 60 | Loss: 5.211 | Accuracy: 0.143\n",
            "Batch 70 | Loss: 5.440 | Accuracy: 0.118\n",
            "Batch 80 | Loss: 5.300 | Accuracy: 0.128\n",
            "Batch 90 | Loss: 5.088 | Accuracy: 0.146\n",
            "Batch 100 | Loss: 5.027 | Accuracy: 0.147\n",
            "Batch 110 | Loss: 5.065 | Accuracy: 0.148\n",
            "Batch 120 | Loss: 5.005 | Accuracy: 0.160\n",
            "Batch 130 | Loss: 5.345 | Accuracy: 0.129\n",
            "Batch 140 | Loss: 5.411 | Accuracy: 0.121\n",
            "Batch 150 | Loss: 5.067 | Accuracy: 0.149\n",
            "Batch 160 | Loss: 5.103 | Accuracy: 0.141\n",
            "Batch 170 | Loss: 5.159 | Accuracy: 0.139\n",
            "Batch 180 | Loss: 5.134 | Accuracy: 0.136\n",
            "Batch 190 | Loss: 5.126 | Accuracy: 0.155\n",
            "Batch 200 | Loss: 4.975 | Accuracy: 0.157\n",
            "Batch 210 | Loss: 4.778 | Accuracy: 0.183\n",
            "Batch 220 | Loss: 5.194 | Accuracy: 0.123\n",
            "Batch 230 | Loss: 5.167 | Accuracy: 0.138\n",
            "Batch 240 | Loss: 5.325 | Accuracy: 0.149\n",
            "Batch 250 | Loss: 5.002 | Accuracy: 0.144\n",
            "Batch 260 | Loss: 5.238 | Accuracy: 0.135\n",
            "Batch 270 | Loss: 5.767 | Accuracy: 0.101\n",
            "Batch 280 | Loss: 4.878 | Accuracy: 0.162\n",
            "Batch 290 | Loss: 5.116 | Accuracy: 0.138\n",
            "Batch 300 | Loss: 5.003 | Accuracy: 0.152\n",
            "Batch 310 | Loss: 4.983 | Accuracy: 0.173\n",
            "Batch 320 | Loss: 5.192 | Accuracy: 0.134\n",
            "Epoch: 05 | Time: 5m 8s\n",
            "\tTrain Loss: 5.148 | Train PPL: 172.096 | Train Acc: 0.139\n",
            "\t Val. Loss: 6.021 |  Val. PPL: 412.005 |  Val. Acc: 0.067 |  Val. BLEU: 0.003\n",
            "Batch 0 | Loss: 4.960 | Accuracy: 0.157\n",
            "Batch 10 | Loss: 4.903 | Accuracy: 0.176\n",
            "Batch 20 | Loss: 5.134 | Accuracy: 0.160\n",
            "Batch 30 | Loss: 5.069 | Accuracy: 0.146\n",
            "Batch 40 | Loss: 5.017 | Accuracy: 0.170\n",
            "Batch 50 | Loss: 5.094 | Accuracy: 0.146\n",
            "Batch 60 | Loss: 5.110 | Accuracy: 0.165\n",
            "Batch 70 | Loss: 4.915 | Accuracy: 0.138\n",
            "Batch 80 | Loss: 4.990 | Accuracy: 0.153\n",
            "Batch 90 | Loss: 5.199 | Accuracy: 0.122\n",
            "Batch 100 | Loss: 5.092 | Accuracy: 0.145\n",
            "Batch 110 | Loss: 5.007 | Accuracy: 0.148\n",
            "Batch 120 | Loss: 5.086 | Accuracy: 0.128\n",
            "Batch 130 | Loss: 4.907 | Accuracy: 0.157\n",
            "Batch 140 | Loss: 4.917 | Accuracy: 0.160\n",
            "Batch 150 | Loss: 4.676 | Accuracy: 0.181\n",
            "Batch 160 | Loss: 5.034 | Accuracy: 0.153\n",
            "Batch 170 | Loss: 5.043 | Accuracy: 0.152\n",
            "Batch 180 | Loss: 5.158 | Accuracy: 0.134\n",
            "Batch 190 | Loss: 4.929 | Accuracy: 0.161\n",
            "Batch 200 | Loss: 5.016 | Accuracy: 0.131\n",
            "Batch 210 | Loss: 5.117 | Accuracy: 0.155\n",
            "Batch 220 | Loss: 4.917 | Accuracy: 0.177\n",
            "Batch 230 | Loss: 5.009 | Accuracy: 0.146\n",
            "Batch 240 | Loss: 5.095 | Accuracy: 0.127\n",
            "Batch 250 | Loss: 5.031 | Accuracy: 0.121\n",
            "Batch 260 | Loss: 5.342 | Accuracy: 0.121\n",
            "Batch 270 | Loss: 5.018 | Accuracy: 0.145\n",
            "Batch 280 | Loss: 5.324 | Accuracy: 0.140\n",
            "Batch 290 | Loss: 4.823 | Accuracy: 0.176\n",
            "Batch 300 | Loss: 5.043 | Accuracy: 0.166\n",
            "Batch 310 | Loss: 5.041 | Accuracy: 0.136\n",
            "Batch 320 | Loss: 4.966 | Accuracy: 0.133\n",
            "Epoch: 06 | Time: 5m 9s\n",
            "\tTrain Loss: 5.076 | Train PPL: 160.172 | Train Acc: 0.144\n",
            "\t Val. Loss: 6.273 |  Val. PPL: 529.825 |  Val. Acc: 0.059 |  Val. BLEU: 0.004\n",
            "Batch 0 | Loss: 4.853 | Accuracy: 0.184\n",
            "Batch 10 | Loss: 4.765 | Accuracy: 0.165\n",
            "Batch 20 | Loss: 5.204 | Accuracy: 0.122\n",
            "Batch 30 | Loss: 4.713 | Accuracy: 0.181\n",
            "Batch 40 | Loss: 4.572 | Accuracy: 0.202\n",
            "Batch 50 | Loss: 4.692 | Accuracy: 0.169\n",
            "Batch 60 | Loss: 4.795 | Accuracy: 0.165\n",
            "Batch 70 | Loss: 5.033 | Accuracy: 0.144\n",
            "Batch 80 | Loss: 4.778 | Accuracy: 0.184\n",
            "Batch 90 | Loss: 4.830 | Accuracy: 0.165\n",
            "Batch 100 | Loss: 4.956 | Accuracy: 0.150\n",
            "Batch 110 | Loss: 5.051 | Accuracy: 0.173\n",
            "Batch 120 | Loss: 5.064 | Accuracy: 0.137\n",
            "Batch 130 | Loss: 5.019 | Accuracy: 0.160\n",
            "Batch 140 | Loss: 5.003 | Accuracy: 0.126\n",
            "Batch 150 | Loss: 5.204 | Accuracy: 0.140\n",
            "Batch 160 | Loss: 5.091 | Accuracy: 0.167\n",
            "Batch 170 | Loss: 5.126 | Accuracy: 0.155\n",
            "Batch 180 | Loss: 4.972 | Accuracy: 0.149\n",
            "Batch 190 | Loss: 5.055 | Accuracy: 0.127\n",
            "Batch 200 | Loss: 5.178 | Accuracy: 0.165\n",
            "Batch 210 | Loss: 4.769 | Accuracy: 0.169\n",
            "Batch 220 | Loss: 5.012 | Accuracy: 0.148\n",
            "Batch 230 | Loss: 5.243 | Accuracy: 0.141\n",
            "Batch 240 | Loss: 5.011 | Accuracy: 0.154\n",
            "Batch 250 | Loss: 5.095 | Accuracy: 0.153\n",
            "Batch 260 | Loss: 4.914 | Accuracy: 0.163\n",
            "Batch 270 | Loss: 5.226 | Accuracy: 0.139\n",
            "Batch 280 | Loss: 4.787 | Accuracy: 0.181\n",
            "Batch 290 | Loss: 5.283 | Accuracy: 0.126\n",
            "Batch 300 | Loss: 4.975 | Accuracy: 0.150\n",
            "Batch 310 | Loss: 5.529 | Accuracy: 0.125\n",
            "Batch 320 | Loss: 5.116 | Accuracy: 0.139\n",
            "Epoch: 07 | Time: 5m 9s\n",
            "\tTrain Loss: 5.026 | Train PPL: 152.261 | Train Acc: 0.147\n",
            "\t Val. Loss: 6.140 |  Val. PPL: 463.918 |  Val. Acc: 0.055 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 5.310 | Accuracy: 0.132\n",
            "Batch 10 | Loss: 4.807 | Accuracy: 0.152\n",
            "Batch 20 | Loss: 5.199 | Accuracy: 0.150\n",
            "Batch 30 | Loss: 4.900 | Accuracy: 0.158\n",
            "Batch 40 | Loss: 5.087 | Accuracy: 0.134\n",
            "Batch 50 | Loss: 5.151 | Accuracy: 0.129\n",
            "Batch 60 | Loss: 4.795 | Accuracy: 0.158\n",
            "Batch 70 | Loss: 5.141 | Accuracy: 0.110\n",
            "Batch 80 | Loss: 4.852 | Accuracy: 0.164\n",
            "Batch 90 | Loss: 5.141 | Accuracy: 0.132\n",
            "Batch 100 | Loss: 5.190 | Accuracy: 0.142\n",
            "Batch 110 | Loss: 5.317 | Accuracy: 0.125\n",
            "Batch 120 | Loss: 5.006 | Accuracy: 0.154\n",
            "Batch 130 | Loss: 4.797 | Accuracy: 0.158\n",
            "Batch 140 | Loss: 4.963 | Accuracy: 0.157\n",
            "Batch 150 | Loss: 4.902 | Accuracy: 0.139\n",
            "Batch 160 | Loss: 5.019 | Accuracy: 0.142\n",
            "Batch 170 | Loss: 5.191 | Accuracy: 0.131\n",
            "Batch 180 | Loss: 4.722 | Accuracy: 0.158\n",
            "Batch 190 | Loss: 5.008 | Accuracy: 0.148\n",
            "Batch 200 | Loss: 5.078 | Accuracy: 0.176\n",
            "Batch 210 | Loss: 5.206 | Accuracy: 0.142\n",
            "Batch 220 | Loss: 5.006 | Accuracy: 0.148\n",
            "Batch 230 | Loss: 4.799 | Accuracy: 0.171\n",
            "Batch 240 | Loss: 5.058 | Accuracy: 0.136\n",
            "Batch 250 | Loss: 4.982 | Accuracy: 0.154\n",
            "Batch 260 | Loss: 5.010 | Accuracy: 0.147\n",
            "Batch 270 | Loss: 5.171 | Accuracy: 0.128\n",
            "Batch 280 | Loss: 5.177 | Accuracy: 0.125\n",
            "Batch 290 | Loss: 4.833 | Accuracy: 0.135\n",
            "Batch 300 | Loss: 5.043 | Accuracy: 0.144\n",
            "Batch 310 | Loss: 5.225 | Accuracy: 0.119\n",
            "Batch 320 | Loss: 4.803 | Accuracy: 0.165\n",
            "Epoch: 08 | Time: 5m 9s\n",
            "\tTrain Loss: 4.998 | Train PPL: 148.077 | Train Acc: 0.147\n",
            "\t Val. Loss: 5.930 |  Val. PPL: 375.980 |  Val. Acc: 0.066 |  Val. BLEU: 0.004\n",
            "Batch 0 | Loss: 5.174 | Accuracy: 0.135\n",
            "Batch 10 | Loss: 5.234 | Accuracy: 0.112\n",
            "Batch 20 | Loss: 4.928 | Accuracy: 0.157\n",
            "Batch 30 | Loss: 4.850 | Accuracy: 0.149\n",
            "Batch 40 | Loss: 5.078 | Accuracy: 0.134\n",
            "Batch 50 | Loss: 4.768 | Accuracy: 0.181\n",
            "Batch 60 | Loss: 4.844 | Accuracy: 0.183\n",
            "Batch 70 | Loss: 4.856 | Accuracy: 0.161\n",
            "Batch 80 | Loss: 5.358 | Accuracy: 0.117\n",
            "Batch 90 | Loss: 4.757 | Accuracy: 0.162\n",
            "Batch 100 | Loss: 5.466 | Accuracy: 0.122\n",
            "Batch 110 | Loss: 4.752 | Accuracy: 0.164\n",
            "Batch 120 | Loss: 4.752 | Accuracy: 0.169\n",
            "Batch 130 | Loss: 4.854 | Accuracy: 0.162\n",
            "Batch 140 | Loss: 4.831 | Accuracy: 0.166\n",
            "Batch 150 | Loss: 4.704 | Accuracy: 0.178\n",
            "Batch 160 | Loss: 4.973 | Accuracy: 0.164\n",
            "Batch 170 | Loss: 5.116 | Accuracy: 0.148\n",
            "Batch 180 | Loss: 5.157 | Accuracy: 0.132\n",
            "Batch 190 | Loss: 5.012 | Accuracy: 0.134\n",
            "Batch 200 | Loss: 5.027 | Accuracy: 0.138\n",
            "Batch 210 | Loss: 5.091 | Accuracy: 0.150\n",
            "Batch 220 | Loss: 5.020 | Accuracy: 0.144\n",
            "Batch 230 | Loss: 5.044 | Accuracy: 0.146\n",
            "Batch 240 | Loss: 4.870 | Accuracy: 0.177\n",
            "Batch 250 | Loss: 4.806 | Accuracy: 0.169\n",
            "Batch 260 | Loss: 5.117 | Accuracy: 0.136\n",
            "Batch 270 | Loss: 5.131 | Accuracy: 0.143\n",
            "Batch 280 | Loss: 4.939 | Accuracy: 0.146\n",
            "Batch 290 | Loss: 4.870 | Accuracy: 0.166\n",
            "Batch 300 | Loss: 5.003 | Accuracy: 0.141\n",
            "Batch 310 | Loss: 5.005 | Accuracy: 0.133\n",
            "Batch 320 | Loss: 4.814 | Accuracy: 0.157\n",
            "Epoch: 09 | Time: 5m 7s\n",
            "\tTrain Loss: 4.947 | Train PPL: 140.725 | Train Acc: 0.153\n",
            "\t Val. Loss: 5.995 |  Val. PPL: 401.282 |  Val. Acc: 0.065 |  Val. BLEU: 0.004\n",
            "Batch 0 | Loss: 5.206 | Accuracy: 0.141\n",
            "Batch 10 | Loss: 5.026 | Accuracy: 0.135\n",
            "Batch 20 | Loss: 5.011 | Accuracy: 0.134\n",
            "Batch 30 | Loss: 4.755 | Accuracy: 0.181\n",
            "Batch 40 | Loss: 4.704 | Accuracy: 0.185\n",
            "Batch 50 | Loss: 5.267 | Accuracy: 0.121\n",
            "Batch 60 | Loss: 4.665 | Accuracy: 0.188\n",
            "Batch 70 | Loss: 5.258 | Accuracy: 0.120\n",
            "Batch 80 | Loss: 4.753 | Accuracy: 0.168\n",
            "Batch 90 | Loss: 5.040 | Accuracy: 0.136\n",
            "Batch 100 | Loss: 5.000 | Accuracy: 0.164\n",
            "Batch 110 | Loss: 4.944 | Accuracy: 0.124\n",
            "Batch 120 | Loss: 5.009 | Accuracy: 0.144\n",
            "Batch 130 | Loss: 4.907 | Accuracy: 0.149\n",
            "Batch 140 | Loss: 4.535 | Accuracy: 0.174\n",
            "Batch 150 | Loss: 4.803 | Accuracy: 0.159\n",
            "Batch 160 | Loss: 4.630 | Accuracy: 0.165\n",
            "Batch 170 | Loss: 5.135 | Accuracy: 0.135\n",
            "Batch 180 | Loss: 4.809 | Accuracy: 0.158\n",
            "Batch 190 | Loss: 4.794 | Accuracy: 0.170\n",
            "Batch 200 | Loss: 4.768 | Accuracy: 0.160\n",
            "Batch 210 | Loss: 4.928 | Accuracy: 0.142\n",
            "Batch 220 | Loss: 4.962 | Accuracy: 0.159\n",
            "Batch 230 | Loss: 4.817 | Accuracy: 0.179\n",
            "Batch 240 | Loss: 4.692 | Accuracy: 0.193\n",
            "Batch 250 | Loss: 4.806 | Accuracy: 0.182\n",
            "Batch 260 | Loss: 4.360 | Accuracy: 0.162\n",
            "Batch 270 | Loss: 4.776 | Accuracy: 0.178\n",
            "Batch 280 | Loss: 4.932 | Accuracy: 0.171\n",
            "Batch 290 | Loss: 5.049 | Accuracy: 0.144\n",
            "Batch 300 | Loss: 4.931 | Accuracy: 0.165\n",
            "Batch 310 | Loss: 4.799 | Accuracy: 0.188\n",
            "Batch 320 | Loss: 4.798 | Accuracy: 0.156\n",
            "Epoch: 10 | Time: 5m 7s\n",
            "\tTrain Loss: 4.905 | Train PPL: 134.923 | Train Acc: 0.157\n",
            "\t Val. Loss: 5.932 |  Val. PPL: 376.995 |  Val. Acc: 0.073 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 5.086 | Accuracy: 0.128\n",
            "Batch 10 | Loss: 4.928 | Accuracy: 0.170\n",
            "Batch 20 | Loss: 4.747 | Accuracy: 0.162\n",
            "Batch 30 | Loss: 4.888 | Accuracy: 0.171\n",
            "Batch 40 | Loss: 4.593 | Accuracy: 0.188\n",
            "Batch 50 | Loss: 4.599 | Accuracy: 0.182\n",
            "Batch 60 | Loss: 5.119 | Accuracy: 0.129\n",
            "Batch 70 | Loss: 4.707 | Accuracy: 0.189\n",
            "Batch 80 | Loss: 4.663 | Accuracy: 0.162\n",
            "Batch 90 | Loss: 4.970 | Accuracy: 0.144\n",
            "Batch 100 | Loss: 5.220 | Accuracy: 0.167\n",
            "Batch 110 | Loss: 5.111 | Accuracy: 0.123\n",
            "Batch 120 | Loss: 4.565 | Accuracy: 0.169\n",
            "Batch 130 | Loss: 4.951 | Accuracy: 0.150\n",
            "Batch 140 | Loss: 5.322 | Accuracy: 0.155\n",
            "Batch 150 | Loss: 4.552 | Accuracy: 0.166\n",
            "Batch 160 | Loss: 4.994 | Accuracy: 0.151\n",
            "Batch 170 | Loss: 4.829 | Accuracy: 0.176\n",
            "Batch 180 | Loss: 5.157 | Accuracy: 0.123\n",
            "Batch 190 | Loss: 4.617 | Accuracy: 0.182\n",
            "Batch 200 | Loss: 4.972 | Accuracy: 0.164\n",
            "Batch 210 | Loss: 4.950 | Accuracy: 0.139\n",
            "Batch 220 | Loss: 5.119 | Accuracy: 0.142\n",
            "Batch 230 | Loss: 4.486 | Accuracy: 0.214\n",
            "Batch 240 | Loss: 4.964 | Accuracy: 0.138\n",
            "Batch 250 | Loss: 4.822 | Accuracy: 0.150\n",
            "Batch 260 | Loss: 4.639 | Accuracy: 0.157\n",
            "Batch 270 | Loss: 5.254 | Accuracy: 0.104\n",
            "Batch 280 | Loss: 4.871 | Accuracy: 0.179\n",
            "Batch 290 | Loss: 4.935 | Accuracy: 0.141\n",
            "Batch 300 | Loss: 4.910 | Accuracy: 0.178\n",
            "Batch 310 | Loss: 4.656 | Accuracy: 0.172\n",
            "Batch 320 | Loss: 4.639 | Accuracy: 0.207\n",
            "Epoch: 11 | Time: 5m 8s\n",
            "\tTrain Loss: 4.860 | Train PPL: 129.029 | Train Acc: 0.161\n",
            "\t Val. Loss: 5.964 |  Val. PPL: 389.007 |  Val. Acc: 0.072 |  Val. BLEU: 0.004\n",
            "Batch 0 | Loss: 4.552 | Accuracy: 0.231\n",
            "Batch 10 | Loss: 4.845 | Accuracy: 0.158\n",
            "Batch 20 | Loss: 4.547 | Accuracy: 0.170\n",
            "Batch 30 | Loss: 4.603 | Accuracy: 0.190\n",
            "Batch 40 | Loss: 4.728 | Accuracy: 0.166\n",
            "Batch 50 | Loss: 4.681 | Accuracy: 0.196\n",
            "Batch 60 | Loss: 4.889 | Accuracy: 0.167\n",
            "Batch 70 | Loss: 4.846 | Accuracy: 0.171\n",
            "Batch 80 | Loss: 5.015 | Accuracy: 0.144\n",
            "Batch 90 | Loss: 4.985 | Accuracy: 0.147\n",
            "Batch 100 | Loss: 4.881 | Accuracy: 0.157\n",
            "Batch 110 | Loss: 4.793 | Accuracy: 0.147\n",
            "Batch 120 | Loss: 4.867 | Accuracy: 0.163\n",
            "Batch 130 | Loss: 4.705 | Accuracy: 0.173\n",
            "Batch 140 | Loss: 4.959 | Accuracy: 0.153\n",
            "Batch 150 | Loss: 4.722 | Accuracy: 0.178\n",
            "Batch 160 | Loss: 4.843 | Accuracy: 0.179\n",
            "Batch 170 | Loss: 4.578 | Accuracy: 0.190\n",
            "Batch 180 | Loss: 4.780 | Accuracy: 0.166\n",
            "Batch 190 | Loss: 4.899 | Accuracy: 0.160\n",
            "Batch 200 | Loss: 4.867 | Accuracy: 0.169\n",
            "Batch 210 | Loss: 4.849 | Accuracy: 0.162\n",
            "Batch 220 | Loss: 4.861 | Accuracy: 0.168\n",
            "Batch 230 | Loss: 4.772 | Accuracy: 0.161\n",
            "Batch 240 | Loss: 4.952 | Accuracy: 0.160\n",
            "Batch 250 | Loss: 4.711 | Accuracy: 0.179\n",
            "Batch 260 | Loss: 5.107 | Accuracy: 0.134\n",
            "Batch 270 | Loss: 4.835 | Accuracy: 0.137\n",
            "Batch 280 | Loss: 4.973 | Accuracy: 0.176\n",
            "Batch 290 | Loss: 4.793 | Accuracy: 0.165\n",
            "Batch 300 | Loss: 4.742 | Accuracy: 0.150\n",
            "Batch 310 | Loss: 4.777 | Accuracy: 0.165\n",
            "Batch 320 | Loss: 4.747 | Accuracy: 0.171\n",
            "Epoch: 12 | Time: 5m 8s\n",
            "\tTrain Loss: 4.826 | Train PPL: 124.738 | Train Acc: 0.164\n",
            "\t Val. Loss: 5.857 |  Val. PPL: 349.714 |  Val. Acc: 0.079 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.763 | Accuracy: 0.168\n",
            "Batch 10 | Loss: 4.847 | Accuracy: 0.169\n",
            "Batch 20 | Loss: 4.765 | Accuracy: 0.187\n",
            "Batch 30 | Loss: 4.778 | Accuracy: 0.173\n",
            "Batch 40 | Loss: 5.304 | Accuracy: 0.127\n",
            "Batch 50 | Loss: 4.886 | Accuracy: 0.157\n",
            "Batch 60 | Loss: 4.938 | Accuracy: 0.162\n",
            "Batch 70 | Loss: 4.892 | Accuracy: 0.142\n",
            "Batch 80 | Loss: 5.073 | Accuracy: 0.153\n",
            "Batch 90 | Loss: 4.964 | Accuracy: 0.135\n",
            "Batch 100 | Loss: 4.762 | Accuracy: 0.180\n",
            "Batch 110 | Loss: 4.602 | Accuracy: 0.202\n",
            "Batch 120 | Loss: 4.753 | Accuracy: 0.144\n",
            "Batch 130 | Loss: 4.561 | Accuracy: 0.184\n",
            "Batch 140 | Loss: 4.901 | Accuracy: 0.151\n",
            "Batch 150 | Loss: 4.862 | Accuracy: 0.163\n",
            "Batch 160 | Loss: 4.971 | Accuracy: 0.171\n",
            "Batch 170 | Loss: 4.766 | Accuracy: 0.194\n",
            "Batch 180 | Loss: 4.519 | Accuracy: 0.205\n",
            "Batch 190 | Loss: 4.595 | Accuracy: 0.190\n",
            "Batch 200 | Loss: 4.998 | Accuracy: 0.149\n",
            "Batch 210 | Loss: 4.847 | Accuracy: 0.167\n",
            "Batch 220 | Loss: 4.890 | Accuracy: 0.164\n",
            "Batch 230 | Loss: 4.650 | Accuracy: 0.147\n",
            "Batch 240 | Loss: 4.658 | Accuracy: 0.181\n",
            "Batch 250 | Loss: 5.023 | Accuracy: 0.160\n",
            "Batch 260 | Loss: 4.537 | Accuracy: 0.186\n",
            "Batch 270 | Loss: 4.948 | Accuracy: 0.151\n",
            "Batch 280 | Loss: 4.762 | Accuracy: 0.179\n",
            "Batch 290 | Loss: 4.435 | Accuracy: 0.179\n",
            "Batch 300 | Loss: 4.339 | Accuracy: 0.186\n",
            "Batch 310 | Loss: 4.877 | Accuracy: 0.137\n",
            "Batch 320 | Loss: 4.540 | Accuracy: 0.201\n",
            "Epoch: 13 | Time: 5m 7s\n",
            "\tTrain Loss: 4.773 | Train PPL: 118.300 | Train Acc: 0.169\n",
            "\t Val. Loss: 5.865 |  Val. PPL: 352.389 |  Val. Acc: 0.074 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.644 | Accuracy: 0.165\n",
            "Batch 10 | Loss: 4.552 | Accuracy: 0.201\n",
            "Batch 20 | Loss: 4.703 | Accuracy: 0.167\n",
            "Batch 30 | Loss: 4.701 | Accuracy: 0.183\n",
            "Batch 40 | Loss: 5.243 | Accuracy: 0.157\n",
            "Batch 50 | Loss: 4.541 | Accuracy: 0.175\n",
            "Batch 60 | Loss: 4.724 | Accuracy: 0.179\n",
            "Batch 70 | Loss: 4.693 | Accuracy: 0.164\n",
            "Batch 80 | Loss: 4.752 | Accuracy: 0.171\n",
            "Batch 90 | Loss: 4.967 | Accuracy: 0.146\n",
            "Batch 100 | Loss: 4.571 | Accuracy: 0.188\n",
            "Batch 110 | Loss: 4.941 | Accuracy: 0.150\n",
            "Batch 120 | Loss: 4.425 | Accuracy: 0.223\n",
            "Batch 130 | Loss: 4.501 | Accuracy: 0.214\n",
            "Batch 140 | Loss: 4.803 | Accuracy: 0.150\n",
            "Batch 150 | Loss: 4.861 | Accuracy: 0.161\n",
            "Batch 160 | Loss: 4.831 | Accuracy: 0.193\n",
            "Batch 170 | Loss: 4.556 | Accuracy: 0.203\n",
            "Batch 180 | Loss: 4.955 | Accuracy: 0.140\n",
            "Batch 190 | Loss: 4.654 | Accuracy: 0.173\n",
            "Batch 200 | Loss: 4.837 | Accuracy: 0.155\n",
            "Batch 210 | Loss: 4.731 | Accuracy: 0.166\n",
            "Batch 220 | Loss: 4.342 | Accuracy: 0.205\n",
            "Batch 230 | Loss: 4.895 | Accuracy: 0.192\n",
            "Batch 240 | Loss: 4.416 | Accuracy: 0.210\n",
            "Batch 250 | Loss: 4.367 | Accuracy: 0.221\n",
            "Batch 260 | Loss: 4.645 | Accuracy: 0.184\n",
            "Batch 270 | Loss: 4.641 | Accuracy: 0.171\n",
            "Batch 280 | Loss: 4.736 | Accuracy: 0.159\n",
            "Batch 290 | Loss: 4.718 | Accuracy: 0.190\n",
            "Batch 300 | Loss: 4.553 | Accuracy: 0.228\n",
            "Batch 310 | Loss: 4.875 | Accuracy: 0.177\n",
            "Batch 320 | Loss: 4.745 | Accuracy: 0.191\n",
            "Epoch: 14 | Time: 5m 7s\n",
            "\tTrain Loss: 4.695 | Train PPL: 109.417 | Train Acc: 0.177\n",
            "\t Val. Loss: 5.883 |  Val. PPL: 358.891 |  Val. Acc: 0.075 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.954 | Accuracy: 0.161\n",
            "Batch 10 | Loss: 4.704 | Accuracy: 0.184\n",
            "Batch 20 | Loss: 4.580 | Accuracy: 0.186\n",
            "Batch 30 | Loss: 4.652 | Accuracy: 0.183\n",
            "Batch 40 | Loss: 4.398 | Accuracy: 0.190\n",
            "Batch 50 | Loss: 4.912 | Accuracy: 0.154\n",
            "Batch 60 | Loss: 4.753 | Accuracy: 0.172\n",
            "Batch 70 | Loss: 4.747 | Accuracy: 0.160\n",
            "Batch 80 | Loss: 4.810 | Accuracy: 0.158\n",
            "Batch 90 | Loss: 4.695 | Accuracy: 0.165\n",
            "Batch 100 | Loss: 4.384 | Accuracy: 0.205\n",
            "Batch 110 | Loss: 4.545 | Accuracy: 0.194\n",
            "Batch 120 | Loss: 4.304 | Accuracy: 0.218\n",
            "Batch 130 | Loss: 4.830 | Accuracy: 0.161\n",
            "Batch 140 | Loss: 4.240 | Accuracy: 0.222\n",
            "Batch 150 | Loss: 4.855 | Accuracy: 0.158\n",
            "Batch 160 | Loss: 4.571 | Accuracy: 0.193\n",
            "Batch 170 | Loss: 4.494 | Accuracy: 0.220\n",
            "Batch 180 | Loss: 4.518 | Accuracy: 0.210\n",
            "Batch 190 | Loss: 4.460 | Accuracy: 0.197\n",
            "Batch 200 | Loss: 4.255 | Accuracy: 0.215\n",
            "Batch 210 | Loss: 4.848 | Accuracy: 0.158\n",
            "Batch 220 | Loss: 4.374 | Accuracy: 0.247\n",
            "Batch 230 | Loss: 4.580 | Accuracy: 0.191\n",
            "Batch 240 | Loss: 4.824 | Accuracy: 0.174\n",
            "Batch 250 | Loss: 4.571 | Accuracy: 0.184\n",
            "Batch 260 | Loss: 4.639 | Accuracy: 0.174\n",
            "Batch 270 | Loss: 4.898 | Accuracy: 0.155\n",
            "Batch 280 | Loss: 4.665 | Accuracy: 0.184\n",
            "Batch 290 | Loss: 4.742 | Accuracy: 0.165\n",
            "Batch 300 | Loss: 4.619 | Accuracy: 0.178\n",
            "Batch 310 | Loss: 4.675 | Accuracy: 0.175\n",
            "Batch 320 | Loss: 4.680 | Accuracy: 0.158\n",
            "Epoch: 15 | Time: 5m 6s\n",
            "\tTrain Loss: 4.675 | Train PPL: 107.270 | Train Acc: 0.179\n",
            "\t Val. Loss: 5.858 |  Val. PPL: 350.116 |  Val. Acc: 0.074 |  Val. BLEU: 0.006\n",
            "Batch 0 | Loss: 4.969 | Accuracy: 0.156\n",
            "Batch 10 | Loss: 4.426 | Accuracy: 0.213\n",
            "Batch 20 | Loss: 4.955 | Accuracy: 0.166\n",
            "Batch 30 | Loss: 4.646 | Accuracy: 0.185\n",
            "Batch 40 | Loss: 4.577 | Accuracy: 0.183\n",
            "Batch 50 | Loss: 4.793 | Accuracy: 0.204\n",
            "Batch 60 | Loss: 4.628 | Accuracy: 0.158\n",
            "Batch 70 | Loss: 4.596 | Accuracy: 0.138\n",
            "Batch 80 | Loss: 4.731 | Accuracy: 0.173\n",
            "Batch 90 | Loss: 4.877 | Accuracy: 0.154\n",
            "Batch 100 | Loss: 4.643 | Accuracy: 0.190\n",
            "Batch 110 | Loss: 4.560 | Accuracy: 0.190\n",
            "Batch 120 | Loss: 4.738 | Accuracy: 0.181\n",
            "Batch 130 | Loss: 4.586 | Accuracy: 0.151\n",
            "Batch 140 | Loss: 4.574 | Accuracy: 0.179\n",
            "Batch 150 | Loss: 4.663 | Accuracy: 0.173\n",
            "Batch 160 | Loss: 4.235 | Accuracy: 0.231\n",
            "Batch 170 | Loss: 4.644 | Accuracy: 0.146\n",
            "Batch 180 | Loss: 4.920 | Accuracy: 0.144\n",
            "Batch 190 | Loss: 4.740 | Accuracy: 0.155\n",
            "Batch 200 | Loss: 4.569 | Accuracy: 0.178\n",
            "Batch 210 | Loss: 4.876 | Accuracy: 0.155\n",
            "Batch 220 | Loss: 4.851 | Accuracy: 0.156\n",
            "Batch 230 | Loss: 4.635 | Accuracy: 0.188\n",
            "Batch 240 | Loss: 4.624 | Accuracy: 0.183\n",
            "Batch 250 | Loss: 4.483 | Accuracy: 0.197\n",
            "Batch 260 | Loss: 4.879 | Accuracy: 0.160\n",
            "Batch 270 | Loss: 4.860 | Accuracy: 0.143\n",
            "Batch 280 | Loss: 4.360 | Accuracy: 0.187\n",
            "Batch 290 | Loss: 4.775 | Accuracy: 0.163\n",
            "Batch 300 | Loss: 4.351 | Accuracy: 0.181\n",
            "Batch 310 | Loss: 4.854 | Accuracy: 0.180\n",
            "Batch 320 | Loss: 4.578 | Accuracy: 0.166\n",
            "Epoch: 16 | Time: 5m 6s\n",
            "\tTrain Loss: 4.658 | Train PPL: 105.438 | Train Acc: 0.179\n",
            "\t Val. Loss: 5.858 |  Val. PPL: 349.976 |  Val. Acc: 0.070 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.871 | Accuracy: 0.152\n",
            "Batch 10 | Loss: 4.339 | Accuracy: 0.215\n",
            "Batch 20 | Loss: 4.709 | Accuracy: 0.181\n",
            "Batch 30 | Loss: 4.998 | Accuracy: 0.163\n",
            "Batch 40 | Loss: 4.625 | Accuracy: 0.191\n",
            "Batch 50 | Loss: 4.844 | Accuracy: 0.147\n",
            "Batch 60 | Loss: 4.858 | Accuracy: 0.175\n",
            "Batch 70 | Loss: 4.490 | Accuracy: 0.204\n",
            "Batch 80 | Loss: 4.620 | Accuracy: 0.174\n",
            "Batch 90 | Loss: 4.435 | Accuracy: 0.186\n",
            "Batch 100 | Loss: 4.732 | Accuracy: 0.175\n",
            "Batch 110 | Loss: 5.011 | Accuracy: 0.136\n",
            "Batch 120 | Loss: 4.658 | Accuracy: 0.170\n",
            "Batch 130 | Loss: 4.477 | Accuracy: 0.194\n",
            "Batch 140 | Loss: 4.327 | Accuracy: 0.228\n",
            "Batch 150 | Loss: 4.682 | Accuracy: 0.172\n",
            "Batch 160 | Loss: 4.379 | Accuracy: 0.190\n",
            "Batch 170 | Loss: 4.704 | Accuracy: 0.167\n",
            "Batch 180 | Loss: 4.739 | Accuracy: 0.165\n",
            "Batch 190 | Loss: 4.624 | Accuracy: 0.204\n",
            "Batch 200 | Loss: 4.624 | Accuracy: 0.182\n",
            "Batch 210 | Loss: 4.821 | Accuracy: 0.166\n",
            "Batch 220 | Loss: 4.390 | Accuracy: 0.209\n",
            "Batch 230 | Loss: 4.469 | Accuracy: 0.195\n",
            "Batch 240 | Loss: 4.405 | Accuracy: 0.223\n",
            "Batch 250 | Loss: 4.770 | Accuracy: 0.186\n",
            "Batch 260 | Loss: 4.508 | Accuracy: 0.175\n",
            "Batch 270 | Loss: 4.439 | Accuracy: 0.206\n",
            "Batch 280 | Loss: 4.336 | Accuracy: 0.213\n",
            "Batch 290 | Loss: 4.628 | Accuracy: 0.170\n",
            "Batch 300 | Loss: 4.749 | Accuracy: 0.175\n",
            "Batch 310 | Loss: 4.448 | Accuracy: 0.190\n",
            "Batch 320 | Loss: 4.651 | Accuracy: 0.166\n",
            "Epoch: 17 | Time: 5m 6s\n",
            "\tTrain Loss: 4.619 | Train PPL: 101.424 | Train Acc: 0.184\n",
            "\t Val. Loss: 5.821 |  Val. PPL: 337.318 |  Val. Acc: 0.083 |  Val. BLEU: 0.004\n",
            "Batch 0 | Loss: 4.579 | Accuracy: 0.190\n",
            "Batch 10 | Loss: 4.481 | Accuracy: 0.181\n",
            "Batch 20 | Loss: 4.532 | Accuracy: 0.185\n",
            "Batch 30 | Loss: 4.221 | Accuracy: 0.236\n",
            "Batch 40 | Loss: 4.453 | Accuracy: 0.201\n",
            "Batch 50 | Loss: 4.717 | Accuracy: 0.174\n",
            "Batch 60 | Loss: 4.665 | Accuracy: 0.187\n",
            "Batch 70 | Loss: 4.455 | Accuracy: 0.209\n",
            "Batch 80 | Loss: 4.641 | Accuracy: 0.194\n",
            "Batch 90 | Loss: 4.483 | Accuracy: 0.190\n",
            "Batch 100 | Loss: 4.516 | Accuracy: 0.201\n",
            "Batch 110 | Loss: 4.625 | Accuracy: 0.186\n",
            "Batch 120 | Loss: 4.758 | Accuracy: 0.168\n",
            "Batch 130 | Loss: 4.666 | Accuracy: 0.172\n",
            "Batch 140 | Loss: 4.646 | Accuracy: 0.161\n",
            "Batch 150 | Loss: 4.742 | Accuracy: 0.178\n",
            "Batch 160 | Loss: 4.564 | Accuracy: 0.173\n",
            "Batch 170 | Loss: 4.575 | Accuracy: 0.172\n",
            "Batch 180 | Loss: 4.583 | Accuracy: 0.214\n",
            "Batch 190 | Loss: 4.106 | Accuracy: 0.278\n",
            "Batch 200 | Loss: 4.887 | Accuracy: 0.165\n",
            "Batch 210 | Loss: 4.678 | Accuracy: 0.176\n",
            "Batch 220 | Loss: 4.723 | Accuracy: 0.188\n",
            "Batch 230 | Loss: 4.576 | Accuracy: 0.210\n",
            "Batch 240 | Loss: 4.850 | Accuracy: 0.177\n",
            "Batch 250 | Loss: 4.536 | Accuracy: 0.196\n",
            "Batch 260 | Loss: 4.681 | Accuracy: 0.166\n",
            "Batch 270 | Loss: 4.754 | Accuracy: 0.170\n",
            "Batch 280 | Loss: 4.438 | Accuracy: 0.218\n",
            "Batch 290 | Loss: 4.264 | Accuracy: 0.212\n",
            "Batch 300 | Loss: 4.713 | Accuracy: 0.170\n",
            "Batch 310 | Loss: 4.599 | Accuracy: 0.186\n",
            "Batch 320 | Loss: 4.439 | Accuracy: 0.192\n",
            "Epoch: 18 | Time: 5m 7s\n",
            "\tTrain Loss: 4.606 | Train PPL: 100.039 | Train Acc: 0.186\n",
            "\t Val. Loss: 5.910 |  Val. PPL: 368.656 |  Val. Acc: 0.068 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.481 | Accuracy: 0.195\n",
            "Batch 10 | Loss: 4.295 | Accuracy: 0.258\n",
            "Batch 20 | Loss: 4.640 | Accuracy: 0.178\n",
            "Batch 30 | Loss: 4.767 | Accuracy: 0.179\n",
            "Batch 40 | Loss: 4.667 | Accuracy: 0.186\n",
            "Batch 50 | Loss: 4.639 | Accuracy: 0.166\n",
            "Batch 60 | Loss: 4.750 | Accuracy: 0.179\n",
            "Batch 70 | Loss: 4.907 | Accuracy: 0.154\n",
            "Batch 80 | Loss: 4.255 | Accuracy: 0.222\n",
            "Batch 90 | Loss: 4.589 | Accuracy: 0.188\n",
            "Batch 100 | Loss: 4.381 | Accuracy: 0.210\n",
            "Batch 110 | Loss: 4.710 | Accuracy: 0.177\n",
            "Batch 120 | Loss: 4.640 | Accuracy: 0.179\n",
            "Batch 130 | Loss: 4.379 | Accuracy: 0.203\n",
            "Batch 140 | Loss: 4.583 | Accuracy: 0.185\n",
            "Batch 150 | Loss: 4.625 | Accuracy: 0.175\n",
            "Batch 160 | Loss: 4.269 | Accuracy: 0.221\n",
            "Batch 170 | Loss: 4.517 | Accuracy: 0.211\n",
            "Batch 180 | Loss: 4.729 | Accuracy: 0.175\n",
            "Batch 190 | Loss: 4.726 | Accuracy: 0.188\n",
            "Batch 200 | Loss: 4.607 | Accuracy: 0.169\n",
            "Batch 210 | Loss: 4.462 | Accuracy: 0.199\n",
            "Batch 220 | Loss: 4.289 | Accuracy: 0.210\n",
            "Batch 230 | Loss: 4.428 | Accuracy: 0.188\n",
            "Batch 240 | Loss: 4.511 | Accuracy: 0.203\n",
            "Batch 250 | Loss: 4.616 | Accuracy: 0.178\n",
            "Batch 260 | Loss: 4.985 | Accuracy: 0.161\n",
            "Batch 270 | Loss: 4.700 | Accuracy: 0.176\n",
            "Batch 280 | Loss: 4.664 | Accuracy: 0.164\n",
            "Batch 290 | Loss: 4.777 | Accuracy: 0.189\n",
            "Batch 300 | Loss: 4.618 | Accuracy: 0.183\n",
            "Batch 310 | Loss: 4.498 | Accuracy: 0.185\n",
            "Batch 320 | Loss: 4.784 | Accuracy: 0.162\n",
            "Epoch: 19 | Time: 5m 6s\n",
            "\tTrain Loss: 4.570 | Train PPL:  96.553 | Train Acc: 0.189\n",
            "\t Val. Loss: 5.848 |  Val. PPL: 346.674 |  Val. Acc: 0.078 |  Val. BLEU: 0.006\n",
            "Batch 0 | Loss: 4.444 | Accuracy: 0.220\n",
            "Batch 10 | Loss: 4.682 | Accuracy: 0.183\n",
            "Batch 20 | Loss: 4.851 | Accuracy: 0.154\n",
            "Batch 30 | Loss: 4.586 | Accuracy: 0.161\n",
            "Batch 40 | Loss: 4.732 | Accuracy: 0.191\n",
            "Batch 50 | Loss: 4.777 | Accuracy: 0.164\n",
            "Batch 60 | Loss: 4.637 | Accuracy: 0.214\n",
            "Batch 70 | Loss: 4.555 | Accuracy: 0.189\n",
            "Batch 80 | Loss: 4.267 | Accuracy: 0.235\n",
            "Batch 90 | Loss: 4.555 | Accuracy: 0.192\n",
            "Batch 100 | Loss: 4.512 | Accuracy: 0.192\n",
            "Batch 110 | Loss: 4.858 | Accuracy: 0.157\n",
            "Batch 120 | Loss: 4.448 | Accuracy: 0.164\n",
            "Batch 130 | Loss: 4.451 | Accuracy: 0.194\n",
            "Batch 140 | Loss: 4.777 | Accuracy: 0.174\n",
            "Batch 150 | Loss: 4.324 | Accuracy: 0.206\n",
            "Batch 160 | Loss: 4.522 | Accuracy: 0.182\n",
            "Batch 170 | Loss: 4.769 | Accuracy: 0.163\n",
            "Batch 180 | Loss: 4.630 | Accuracy: 0.184\n",
            "Batch 190 | Loss: 4.664 | Accuracy: 0.163\n",
            "Batch 200 | Loss: 4.496 | Accuracy: 0.179\n",
            "Batch 210 | Loss: 4.275 | Accuracy: 0.207\n",
            "Batch 220 | Loss: 4.528 | Accuracy: 0.199\n",
            "Batch 230 | Loss: 4.585 | Accuracy: 0.188\n",
            "Batch 240 | Loss: 4.677 | Accuracy: 0.179\n",
            "Batch 250 | Loss: 4.214 | Accuracy: 0.217\n",
            "Batch 260 | Loss: 4.594 | Accuracy: 0.186\n",
            "Batch 270 | Loss: 4.738 | Accuracy: 0.183\n",
            "Batch 280 | Loss: 4.415 | Accuracy: 0.190\n",
            "Batch 290 | Loss: 4.489 | Accuracy: 0.218\n",
            "Batch 300 | Loss: 4.416 | Accuracy: 0.186\n",
            "Batch 310 | Loss: 4.838 | Accuracy: 0.161\n",
            "Batch 320 | Loss: 4.567 | Accuracy: 0.184\n",
            "Epoch: 20 | Time: 5m 7s\n",
            "\tTrain Loss: 4.547 | Train PPL:  94.355 | Train Acc: 0.191\n",
            "\t Val. Loss: 5.876 |  Val. PPL: 356.305 |  Val. Acc: 0.068 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.508 | Accuracy: 0.176\n",
            "Batch 10 | Loss: 4.616 | Accuracy: 0.187\n",
            "Batch 20 | Loss: 4.580 | Accuracy: 0.175\n",
            "Batch 30 | Loss: 4.404 | Accuracy: 0.205\n",
            "Batch 40 | Loss: 4.613 | Accuracy: 0.189\n",
            "Batch 50 | Loss: 4.578 | Accuracy: 0.186\n",
            "Batch 60 | Loss: 4.307 | Accuracy: 0.240\n",
            "Batch 70 | Loss: 4.646 | Accuracy: 0.186\n",
            "Batch 80 | Loss: 4.532 | Accuracy: 0.182\n",
            "Batch 90 | Loss: 4.439 | Accuracy: 0.168\n",
            "Batch 100 | Loss: 3.988 | Accuracy: 0.250\n",
            "Batch 110 | Loss: 4.154 | Accuracy: 0.248\n",
            "Batch 120 | Loss: 4.642 | Accuracy: 0.166\n",
            "Batch 130 | Loss: 4.366 | Accuracy: 0.205\n",
            "Batch 140 | Loss: 4.460 | Accuracy: 0.184\n",
            "Batch 150 | Loss: 4.360 | Accuracy: 0.205\n",
            "Batch 160 | Loss: 4.529 | Accuracy: 0.192\n",
            "Batch 170 | Loss: 4.411 | Accuracy: 0.217\n",
            "Batch 180 | Loss: 4.534 | Accuracy: 0.185\n",
            "Batch 190 | Loss: 4.035 | Accuracy: 0.269\n",
            "Batch 200 | Loss: 4.760 | Accuracy: 0.165\n",
            "Batch 210 | Loss: 4.578 | Accuracy: 0.175\n",
            "Batch 220 | Loss: 4.157 | Accuracy: 0.245\n",
            "Batch 230 | Loss: 4.503 | Accuracy: 0.189\n",
            "Batch 240 | Loss: 4.765 | Accuracy: 0.164\n",
            "Batch 250 | Loss: 4.613 | Accuracy: 0.177\n",
            "Batch 260 | Loss: 4.352 | Accuracy: 0.208\n",
            "Batch 270 | Loss: 4.474 | Accuracy: 0.189\n",
            "Batch 280 | Loss: 4.548 | Accuracy: 0.202\n",
            "Batch 290 | Loss: 4.375 | Accuracy: 0.224\n",
            "Batch 300 | Loss: 4.903 | Accuracy: 0.145\n",
            "Batch 310 | Loss: 4.836 | Accuracy: 0.186\n",
            "Batch 320 | Loss: 4.472 | Accuracy: 0.207\n",
            "Epoch: 21 | Time: 5m 6s\n",
            "\tTrain Loss: 4.523 | Train PPL:  92.141 | Train Acc: 0.193\n",
            "\t Val. Loss: 5.840 |  Val. PPL: 343.618 |  Val. Acc: 0.078 |  Val. BLEU: 0.005\n",
            "Batch 0 | Loss: 4.637 | Accuracy: 0.201\n",
            "Batch 10 | Loss: 4.427 | Accuracy: 0.196\n",
            "Batch 20 | Loss: 4.397 | Accuracy: 0.194\n",
            "Batch 30 | Loss: 4.874 | Accuracy: 0.148\n",
            "Batch 40 | Loss: 4.128 | Accuracy: 0.190\n",
            "Batch 50 | Loss: 4.717 | Accuracy: 0.178\n",
            "Batch 60 | Loss: 4.608 | Accuracy: 0.196\n",
            "Batch 70 | Loss: 4.543 | Accuracy: 0.181\n",
            "Batch 80 | Loss: 4.689 | Accuracy: 0.176\n",
            "Batch 90 | Loss: 4.417 | Accuracy: 0.202\n",
            "Batch 100 | Loss: 4.849 | Accuracy: 0.143\n",
            "Batch 110 | Loss: 4.608 | Accuracy: 0.171\n",
            "Batch 120 | Loss: 4.518 | Accuracy: 0.215\n",
            "Batch 130 | Loss: 4.548 | Accuracy: 0.184\n",
            "Batch 140 | Loss: 4.442 | Accuracy: 0.172\n",
            "Batch 150 | Loss: 4.282 | Accuracy: 0.231\n",
            "Batch 160 | Loss: 4.355 | Accuracy: 0.215\n",
            "Batch 170 | Loss: 4.530 | Accuracy: 0.220\n",
            "Batch 180 | Loss: 4.534 | Accuracy: 0.191\n",
            "Batch 190 | Loss: 4.274 | Accuracy: 0.194\n",
            "Batch 200 | Loss: 4.618 | Accuracy: 0.165\n",
            "Batch 210 | Loss: 4.352 | Accuracy: 0.200\n",
            "Batch 220 | Loss: 4.606 | Accuracy: 0.192\n",
            "Batch 230 | Loss: 4.938 | Accuracy: 0.181\n",
            "Batch 240 | Loss: 4.351 | Accuracy: 0.225\n",
            "Batch 250 | Loss: 4.601 | Accuracy: 0.170\n",
            "Batch 260 | Loss: 4.603 | Accuracy: 0.211\n",
            "Batch 270 | Loss: 4.538 | Accuracy: 0.194\n",
            "Batch 280 | Loss: 4.690 | Accuracy: 0.198\n",
            "Batch 290 | Loss: 4.832 | Accuracy: 0.170\n",
            "Batch 300 | Loss: 4.438 | Accuracy: 0.223\n",
            "Batch 310 | Loss: 4.783 | Accuracy: 0.174\n",
            "Batch 320 | Loss: 4.554 | Accuracy: 0.187\n",
            "Epoch: 22 | Time: 5m 7s\n",
            "\tTrain Loss: 4.513 | Train PPL:  91.152 | Train Acc: 0.195\n",
            "\t Val. Loss: 5.894 |  Val. PPL: 363.010 |  Val. Acc: 0.066 |  Val. BLEU: 0.006\n",
            "Batch 0 | Loss: 4.667 | Accuracy: 0.195\n",
            "Batch 10 | Loss: 4.316 | Accuracy: 0.205\n",
            "Batch 20 | Loss: 4.665 | Accuracy: 0.205\n",
            "Batch 30 | Loss: 4.444 | Accuracy: 0.198\n",
            "Batch 40 | Loss: 4.507 | Accuracy: 0.206\n",
            "Batch 50 | Loss: 4.671 | Accuracy: 0.203\n",
            "Batch 60 | Loss: 4.506 | Accuracy: 0.221\n",
            "Batch 70 | Loss: 4.528 | Accuracy: 0.171\n",
            "Batch 80 | Loss: 4.409 | Accuracy: 0.220\n",
            "Batch 90 | Loss: 4.479 | Accuracy: 0.195\n",
            "Batch 100 | Loss: 4.669 | Accuracy: 0.164\n",
            "Batch 110 | Loss: 4.530 | Accuracy: 0.192\n",
            "Batch 120 | Loss: 4.413 | Accuracy: 0.222\n",
            "Batch 130 | Loss: 4.812 | Accuracy: 0.178\n",
            "Batch 140 | Loss: 4.468 | Accuracy: 0.197\n",
            "Batch 150 | Loss: 4.276 | Accuracy: 0.213\n",
            "Batch 160 | Loss: 4.877 | Accuracy: 0.156\n",
            "Batch 170 | Loss: 4.433 | Accuracy: 0.203\n",
            "Batch 180 | Loss: 4.467 | Accuracy: 0.210\n",
            "Batch 190 | Loss: 4.252 | Accuracy: 0.231\n",
            "Batch 200 | Loss: 4.403 | Accuracy: 0.171\n",
            "Batch 210 | Loss: 4.501 | Accuracy: 0.205\n",
            "Batch 220 | Loss: 4.728 | Accuracy: 0.145\n",
            "Batch 230 | Loss: 4.398 | Accuracy: 0.213\n",
            "Batch 240 | Loss: 4.298 | Accuracy: 0.241\n",
            "Batch 250 | Loss: 4.427 | Accuracy: 0.222\n",
            "Batch 260 | Loss: 4.232 | Accuracy: 0.220\n",
            "Batch 270 | Loss: 4.895 | Accuracy: 0.150\n",
            "Batch 280 | Loss: 4.503 | Accuracy: 0.205\n",
            "Batch 290 | Loss: 4.434 | Accuracy: 0.201\n",
            "Batch 300 | Loss: 4.419 | Accuracy: 0.192\n",
            "Batch 310 | Loss: 4.714 | Accuracy: 0.166\n",
            "Batch 320 | Loss: 4.453 | Accuracy: 0.180\n",
            "Epoch: 23 | Time: 5m 6s\n",
            "\tTrain Loss: 4.483 | Train PPL:  88.516 | Train Acc: 0.198\n",
            "\t Val. Loss: 5.889 |  Val. PPL: 361.194 |  Val. Acc: 0.071 |  Val. BLEU: 0.006\n",
            "Batch 0 | Loss: 4.263 | Accuracy: 0.216\n",
            "Batch 10 | Loss: 4.724 | Accuracy: 0.168\n",
            "Batch 20 | Loss: 4.443 | Accuracy: 0.202\n",
            "Batch 30 | Loss: 4.927 | Accuracy: 0.165\n",
            "Batch 40 | Loss: 4.387 | Accuracy: 0.196\n",
            "Batch 50 | Loss: 4.343 | Accuracy: 0.215\n",
            "Batch 60 | Loss: 4.675 | Accuracy: 0.168\n",
            "Batch 70 | Loss: 4.388 | Accuracy: 0.197\n",
            "Batch 80 | Loss: 4.030 | Accuracy: 0.228\n",
            "Batch 90 | Loss: 4.593 | Accuracy: 0.209\n",
            "Batch 100 | Loss: 4.762 | Accuracy: 0.167\n",
            "Batch 110 | Loss: 4.355 | Accuracy: 0.216\n",
            "Batch 120 | Loss: 4.699 | Accuracy: 0.163\n",
            "Batch 130 | Loss: 4.481 | Accuracy: 0.193\n",
            "Batch 140 | Loss: 4.684 | Accuracy: 0.167\n",
            "Batch 150 | Loss: 4.468 | Accuracy: 0.202\n",
            "Batch 160 | Loss: 4.412 | Accuracy: 0.191\n",
            "Batch 170 | Loss: 4.514 | Accuracy: 0.188\n",
            "Batch 180 | Loss: 4.246 | Accuracy: 0.227\n",
            "Batch 190 | Loss: 4.559 | Accuracy: 0.179\n",
            "Batch 200 | Loss: 4.896 | Accuracy: 0.164\n",
            "Batch 210 | Loss: 4.678 | Accuracy: 0.164\n",
            "Batch 220 | Loss: 4.546 | Accuracy: 0.192\n",
            "Batch 230 | Loss: 4.660 | Accuracy: 0.176\n",
            "Batch 240 | Loss: 4.379 | Accuracy: 0.194\n",
            "Batch 250 | Loss: 4.629 | Accuracy: 0.189\n",
            "Batch 260 | Loss: 4.879 | Accuracy: 0.147\n",
            "Batch 270 | Loss: 4.568 | Accuracy: 0.189\n",
            "Batch 280 | Loss: 4.456 | Accuracy: 0.180\n",
            "Batch 290 | Loss: 4.568 | Accuracy: 0.216\n",
            "Batch 300 | Loss: 4.598 | Accuracy: 0.178\n",
            "Batch 310 | Loss: 4.757 | Accuracy: 0.165\n",
            "Batch 320 | Loss: 4.270 | Accuracy: 0.237\n",
            "Epoch: 24 | Time: 5m 7s\n",
            "\tTrain Loss: 4.468 | Train PPL:  87.203 | Train Acc: 0.198\n",
            "\t Val. Loss: 5.855 |  Val. PPL: 349.131 |  Val. Acc: 0.077 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.428 | Accuracy: 0.194\n",
            "Batch 10 | Loss: 4.526 | Accuracy: 0.182\n",
            "Batch 20 | Loss: 4.188 | Accuracy: 0.205\n",
            "Batch 30 | Loss: 3.971 | Accuracy: 0.248\n",
            "Batch 40 | Loss: 4.349 | Accuracy: 0.223\n",
            "Batch 50 | Loss: 4.272 | Accuracy: 0.223\n",
            "Batch 60 | Loss: 4.595 | Accuracy: 0.166\n",
            "Batch 70 | Loss: 4.441 | Accuracy: 0.188\n",
            "Batch 80 | Loss: 4.500 | Accuracy: 0.193\n",
            "Batch 90 | Loss: 4.258 | Accuracy: 0.225\n",
            "Batch 100 | Loss: 4.317 | Accuracy: 0.232\n",
            "Batch 110 | Loss: 4.519 | Accuracy: 0.170\n",
            "Batch 120 | Loss: 4.242 | Accuracy: 0.210\n",
            "Batch 130 | Loss: 4.458 | Accuracy: 0.189\n",
            "Batch 140 | Loss: 4.300 | Accuracy: 0.237\n",
            "Batch 150 | Loss: 4.577 | Accuracy: 0.190\n",
            "Batch 160 | Loss: 4.470 | Accuracy: 0.206\n",
            "Batch 170 | Loss: 4.233 | Accuracy: 0.222\n",
            "Batch 180 | Loss: 4.707 | Accuracy: 0.187\n",
            "Batch 190 | Loss: 4.043 | Accuracy: 0.253\n",
            "Batch 200 | Loss: 4.445 | Accuracy: 0.197\n",
            "Batch 210 | Loss: 4.512 | Accuracy: 0.183\n",
            "Batch 220 | Loss: 4.720 | Accuracy: 0.174\n",
            "Batch 230 | Loss: 4.536 | Accuracy: 0.184\n",
            "Batch 240 | Loss: 4.204 | Accuracy: 0.230\n",
            "Batch 250 | Loss: 4.636 | Accuracy: 0.187\n",
            "Batch 260 | Loss: 4.403 | Accuracy: 0.221\n",
            "Batch 270 | Loss: 4.051 | Accuracy: 0.253\n",
            "Batch 280 | Loss: 4.198 | Accuracy: 0.197\n",
            "Batch 290 | Loss: 4.568 | Accuracy: 0.203\n",
            "Batch 300 | Loss: 4.316 | Accuracy: 0.209\n",
            "Batch 310 | Loss: 4.672 | Accuracy: 0.173\n",
            "Batch 320 | Loss: 4.401 | Accuracy: 0.216\n",
            "Epoch: 25 | Time: 5m 7s\n",
            "\tTrain Loss: 4.419 | Train PPL:  82.972 | Train Acc: 0.204\n",
            "\t Val. Loss: 5.844 |  Val. PPL: 345.319 |  Val. Acc: 0.078 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.290 | Accuracy: 0.222\n",
            "Batch 10 | Loss: 4.384 | Accuracy: 0.193\n",
            "Batch 20 | Loss: 4.606 | Accuracy: 0.186\n",
            "Batch 30 | Loss: 4.833 | Accuracy: 0.153\n",
            "Batch 40 | Loss: 4.220 | Accuracy: 0.222\n",
            "Batch 50 | Loss: 4.426 | Accuracy: 0.201\n",
            "Batch 60 | Loss: 4.349 | Accuracy: 0.186\n",
            "Batch 70 | Loss: 4.320 | Accuracy: 0.233\n",
            "Batch 80 | Loss: 4.066 | Accuracy: 0.240\n",
            "Batch 90 | Loss: 4.411 | Accuracy: 0.206\n",
            "Batch 100 | Loss: 4.249 | Accuracy: 0.210\n",
            "Batch 110 | Loss: 4.184 | Accuracy: 0.235\n",
            "Batch 120 | Loss: 4.537 | Accuracy: 0.204\n",
            "Batch 130 | Loss: 4.404 | Accuracy: 0.203\n",
            "Batch 140 | Loss: 4.061 | Accuracy: 0.263\n",
            "Batch 150 | Loss: 4.245 | Accuracy: 0.219\n",
            "Batch 160 | Loss: 4.276 | Accuracy: 0.218\n",
            "Batch 170 | Loss: 4.438 | Accuracy: 0.176\n",
            "Batch 180 | Loss: 4.642 | Accuracy: 0.185\n",
            "Batch 190 | Loss: 4.050 | Accuracy: 0.259\n",
            "Batch 200 | Loss: 4.357 | Accuracy: 0.202\n",
            "Batch 210 | Loss: 4.431 | Accuracy: 0.191\n",
            "Batch 220 | Loss: 4.349 | Accuracy: 0.216\n",
            "Batch 230 | Loss: 4.240 | Accuracy: 0.188\n",
            "Batch 240 | Loss: 4.343 | Accuracy: 0.212\n",
            "Batch 250 | Loss: 4.147 | Accuracy: 0.247\n",
            "Batch 260 | Loss: 4.271 | Accuracy: 0.238\n",
            "Batch 270 | Loss: 4.386 | Accuracy: 0.220\n",
            "Batch 280 | Loss: 4.188 | Accuracy: 0.207\n",
            "Batch 290 | Loss: 4.276 | Accuracy: 0.232\n",
            "Batch 300 | Loss: 4.514 | Accuracy: 0.195\n",
            "Batch 310 | Loss: 4.244 | Accuracy: 0.216\n",
            "Batch 320 | Loss: 4.786 | Accuracy: 0.161\n",
            "Epoch: 26 | Time: 5m 7s\n",
            "\tTrain Loss: 4.366 | Train PPL:  78.728 | Train Acc: 0.210\n",
            "\t Val. Loss: 5.867 |  Val. PPL: 353.324 |  Val. Acc: 0.079 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.336 | Accuracy: 0.196\n",
            "Batch 10 | Loss: 4.225 | Accuracy: 0.242\n",
            "Batch 20 | Loss: 4.416 | Accuracy: 0.210\n",
            "Batch 30 | Loss: 4.357 | Accuracy: 0.221\n",
            "Batch 40 | Loss: 4.389 | Accuracy: 0.207\n",
            "Batch 50 | Loss: 4.316 | Accuracy: 0.225\n",
            "Batch 60 | Loss: 4.837 | Accuracy: 0.191\n",
            "Batch 70 | Loss: 4.548 | Accuracy: 0.182\n",
            "Batch 80 | Loss: 4.716 | Accuracy: 0.192\n",
            "Batch 90 | Loss: 4.504 | Accuracy: 0.166\n",
            "Batch 100 | Loss: 4.034 | Accuracy: 0.227\n",
            "Batch 110 | Loss: 4.595 | Accuracy: 0.185\n",
            "Batch 120 | Loss: 4.181 | Accuracy: 0.204\n",
            "Batch 130 | Loss: 4.584 | Accuracy: 0.191\n",
            "Batch 140 | Loss: 4.251 | Accuracy: 0.219\n",
            "Batch 150 | Loss: 4.372 | Accuracy: 0.201\n",
            "Batch 160 | Loss: 4.347 | Accuracy: 0.219\n",
            "Batch 170 | Loss: 4.397 | Accuracy: 0.182\n",
            "Batch 180 | Loss: 4.047 | Accuracy: 0.255\n",
            "Batch 190 | Loss: 4.275 | Accuracy: 0.233\n",
            "Batch 200 | Loss: 4.516 | Accuracy: 0.197\n",
            "Batch 210 | Loss: 4.331 | Accuracy: 0.201\n",
            "Batch 220 | Loss: 4.404 | Accuracy: 0.217\n",
            "Batch 230 | Loss: 4.696 | Accuracy: 0.185\n",
            "Batch 240 | Loss: 4.209 | Accuracy: 0.240\n",
            "Batch 250 | Loss: 4.217 | Accuracy: 0.225\n",
            "Batch 260 | Loss: 4.284 | Accuracy: 0.223\n",
            "Batch 270 | Loss: 4.337 | Accuracy: 0.205\n",
            "Batch 280 | Loss: 4.441 | Accuracy: 0.199\n",
            "Batch 290 | Loss: 4.134 | Accuracy: 0.241\n",
            "Batch 300 | Loss: 4.500 | Accuracy: 0.189\n",
            "Batch 310 | Loss: 4.238 | Accuracy: 0.231\n",
            "Batch 320 | Loss: 3.932 | Accuracy: 0.260\n",
            "Epoch: 27 | Time: 5m 7s\n",
            "\tTrain Loss: 4.345 | Train PPL:  77.124 | Train Acc: 0.212\n",
            "\t Val. Loss: 5.835 |  Val. PPL: 341.903 |  Val. Acc: 0.081 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.400 | Accuracy: 0.228\n",
            "Batch 10 | Loss: 4.551 | Accuracy: 0.163\n",
            "Batch 20 | Loss: 4.306 | Accuracy: 0.230\n",
            "Batch 30 | Loss: 4.261 | Accuracy: 0.235\n",
            "Batch 40 | Loss: 4.270 | Accuracy: 0.232\n",
            "Batch 50 | Loss: 4.209 | Accuracy: 0.216\n",
            "Batch 60 | Loss: 4.331 | Accuracy: 0.200\n",
            "Batch 70 | Loss: 4.377 | Accuracy: 0.209\n",
            "Batch 80 | Loss: 4.275 | Accuracy: 0.216\n",
            "Batch 90 | Loss: 4.389 | Accuracy: 0.208\n",
            "Batch 100 | Loss: 4.334 | Accuracy: 0.214\n",
            "Batch 110 | Loss: 4.096 | Accuracy: 0.240\n",
            "Batch 120 | Loss: 4.372 | Accuracy: 0.173\n",
            "Batch 130 | Loss: 4.042 | Accuracy: 0.269\n",
            "Batch 140 | Loss: 4.419 | Accuracy: 0.167\n",
            "Batch 150 | Loss: 4.519 | Accuracy: 0.191\n",
            "Batch 160 | Loss: 4.622 | Accuracy: 0.191\n",
            "Batch 170 | Loss: 4.722 | Accuracy: 0.187\n",
            "Batch 180 | Loss: 4.157 | Accuracy: 0.227\n",
            "Batch 190 | Loss: 4.014 | Accuracy: 0.281\n",
            "Batch 200 | Loss: 4.219 | Accuracy: 0.237\n",
            "Batch 210 | Loss: 4.139 | Accuracy: 0.217\n",
            "Batch 220 | Loss: 4.194 | Accuracy: 0.209\n",
            "Batch 230 | Loss: 4.194 | Accuracy: 0.217\n",
            "Batch 240 | Loss: 4.330 | Accuracy: 0.204\n",
            "Batch 250 | Loss: 4.308 | Accuracy: 0.206\n",
            "Batch 260 | Loss: 4.470 | Accuracy: 0.193\n",
            "Batch 270 | Loss: 4.237 | Accuracy: 0.238\n",
            "Batch 280 | Loss: 4.509 | Accuracy: 0.185\n",
            "Batch 290 | Loss: 4.540 | Accuracy: 0.191\n",
            "Batch 300 | Loss: 4.120 | Accuracy: 0.279\n",
            "Batch 310 | Loss: 4.294 | Accuracy: 0.221\n",
            "Batch 320 | Loss: 4.123 | Accuracy: 0.215\n",
            "Epoch: 28 | Time: 5m 7s\n",
            "\tTrain Loss: 4.332 | Train PPL:  76.102 | Train Acc: 0.213\n",
            "\t Val. Loss: 5.863 |  Val. PPL: 351.713 |  Val. Acc: 0.077 |  Val. BLEU: 0.007\n",
            "Batch 0 | Loss: 4.196 | Accuracy: 0.221\n",
            "Batch 10 | Loss: 4.240 | Accuracy: 0.228\n",
            "Batch 20 | Loss: 4.316 | Accuracy: 0.199\n",
            "Batch 30 | Loss: 4.111 | Accuracy: 0.237\n",
            "Batch 40 | Loss: 3.892 | Accuracy: 0.265\n",
            "Batch 50 | Loss: 4.372 | Accuracy: 0.214\n",
            "Batch 60 | Loss: 4.488 | Accuracy: 0.198\n",
            "Batch 70 | Loss: 4.714 | Accuracy: 0.189\n",
            "Batch 80 | Loss: 4.541 | Accuracy: 0.182\n",
            "Batch 90 | Loss: 4.429 | Accuracy: 0.210\n",
            "Batch 100 | Loss: 4.375 | Accuracy: 0.186\n",
            "Batch 110 | Loss: 3.900 | Accuracy: 0.279\n",
            "Batch 120 | Loss: 3.998 | Accuracy: 0.264\n",
            "Batch 130 | Loss: 4.551 | Accuracy: 0.189\n",
            "Batch 140 | Loss: 4.530 | Accuracy: 0.189\n",
            "Batch 150 | Loss: 4.248 | Accuracy: 0.219\n",
            "Batch 160 | Loss: 4.664 | Accuracy: 0.178\n",
            "Batch 170 | Loss: 4.283 | Accuracy: 0.230\n",
            "Batch 180 | Loss: 4.251 | Accuracy: 0.185\n",
            "Batch 190 | Loss: 4.281 | Accuracy: 0.218\n",
            "Batch 200 | Loss: 4.391 | Accuracy: 0.183\n",
            "Batch 210 | Loss: 4.206 | Accuracy: 0.197\n",
            "Batch 220 | Loss: 4.305 | Accuracy: 0.233\n",
            "Batch 230 | Loss: 4.266 | Accuracy: 0.228\n",
            "Batch 240 | Loss: 4.090 | Accuracy: 0.244\n",
            "Batch 250 | Loss: 3.882 | Accuracy: 0.277\n",
            "Batch 260 | Loss: 4.045 | Accuracy: 0.247\n",
            "Batch 270 | Loss: 4.344 | Accuracy: 0.220\n",
            "Batch 280 | Loss: 4.347 | Accuracy: 0.215\n",
            "Batch 290 | Loss: 4.230 | Accuracy: 0.224\n",
            "Batch 300 | Loss: 4.522 | Accuracy: 0.205\n",
            "Batch 310 | Loss: 4.410 | Accuracy: 0.193\n",
            "Batch 320 | Loss: 4.297 | Accuracy: 0.228\n",
            "Epoch: 29 | Time: 5m 7s\n",
            "\tTrain Loss: 4.313 | Train PPL:  74.687 | Train Acc: 0.215\n",
            "\t Val. Loss: 5.873 |  Val. PPL: 355.276 |  Val. Acc: 0.077 |  Val. BLEU: 0.006\n",
            "Batch 0 | Loss: 4.688 | Accuracy: 0.191\n",
            "Batch 10 | Loss: 4.350 | Accuracy: 0.221\n",
            "Batch 20 | Loss: 4.507 | Accuracy: 0.205\n",
            "Batch 30 | Loss: 4.387 | Accuracy: 0.181\n",
            "Batch 40 | Loss: 4.347 | Accuracy: 0.211\n",
            "Batch 50 | Loss: 4.218 | Accuracy: 0.244\n",
            "Batch 60 | Loss: 4.036 | Accuracy: 0.244\n",
            "Batch 70 | Loss: 4.390 | Accuracy: 0.202\n",
            "Batch 80 | Loss: 4.024 | Accuracy: 0.232\n",
            "Batch 90 | Loss: 4.337 | Accuracy: 0.185\n",
            "Batch 100 | Loss: 4.156 | Accuracy: 0.239\n",
            "Batch 110 | Loss: 4.058 | Accuracy: 0.230\n",
            "Batch 120 | Loss: 4.470 | Accuracy: 0.197\n",
            "Batch 130 | Loss: 4.369 | Accuracy: 0.206\n",
            "Batch 140 | Loss: 4.304 | Accuracy: 0.225\n",
            "Batch 150 | Loss: 4.009 | Accuracy: 0.245\n",
            "Batch 160 | Loss: 4.062 | Accuracy: 0.243\n",
            "Batch 170 | Loss: 4.070 | Accuracy: 0.273\n",
            "Batch 180 | Loss: 4.160 | Accuracy: 0.244\n",
            "Batch 190 | Loss: 4.208 | Accuracy: 0.227\n",
            "Batch 200 | Loss: 4.548 | Accuracy: 0.209\n",
            "Batch 210 | Loss: 3.853 | Accuracy: 0.256\n",
            "Batch 220 | Loss: 4.276 | Accuracy: 0.212\n",
            "Batch 230 | Loss: 4.314 | Accuracy: 0.232\n",
            "Batch 240 | Loss: 3.934 | Accuracy: 0.259\n",
            "Batch 250 | Loss: 4.442 | Accuracy: 0.191\n",
            "Batch 260 | Loss: 4.251 | Accuracy: 0.251\n",
            "Batch 270 | Loss: 4.439 | Accuracy: 0.213\n",
            "Batch 280 | Loss: 4.689 | Accuracy: 0.175\n",
            "Batch 290 | Loss: 4.175 | Accuracy: 0.232\n",
            "Batch 300 | Loss: 4.734 | Accuracy: 0.149\n",
            "Batch 310 | Loss: 4.366 | Accuracy: 0.196\n",
            "Batch 320 | Loss: 4.225 | Accuracy: 0.221\n",
            "Epoch: 30 | Time: 5m 7s\n",
            "\tTrain Loss: 4.310 | Train PPL:  74.447 | Train Acc: 0.214\n",
            "\t Val. Loss: 5.913 |  Val. PPL: 369.961 |  Val. Acc: 0.074 |  Val. BLEU: 0.007\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.17145983119724914, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98fa242aeed44c60a50baacea965c18b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▂▃▄▄▄▃▃▅▅▅▃▄▃▃▅▅▆▇▆▆▅▆▆▅▇▆▆▇▆▆▆▇▅▆▆█▇▇▇</td></tr><tr><td>batch_loss</td><td>█▆▅▅▅▅▆▅▄▃▄▅▄▄▄▄▄▃▃▃▃▃▃▃▄▃▂▃▂▂▂▃▂▃▂▂▁▁▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time_mins</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_time_secs</td><td>▃▃▃▃▆███▃▃▆▆▃▃▁▁▁▃▁▃▁▃▁▃▃▃▃▃▃▃</td></tr><tr><td>train_accuracy</td><td>▁▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>valid_accuracy</td><td>▃▁▅▃▄▂▂▄▄▆▅▇▆▆▆▅█▄▇▅▇▄▅▆▇▇▇▆▇▆</td></tr><tr><td>valid_bleu</td><td>▁▂▁▂▃▄▅▃▃▆▄▅▅▅▆▅▄█▆▆▆▆▆▇▇█▇█▇█</td></tr><tr><td>valid_loss</td><td>▅▅▄▄▄█▆▃▄▃▃▂▂▂▂▂▁▂▁▂▁▂▂▂▁▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>0.22593</td></tr><tr><td>batch_loss</td><td>4.54598</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>epoch_time_mins</td><td>5</td></tr><tr><td>epoch_time_secs</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.2142</td></tr><tr><td>train_loss</td><td>4.31009</td></tr><tr><td>valid_accuracy</td><td>0.07438</td></tr><tr><td>valid_bleu</td><td>0.00717</td></tr><tr><td>valid_loss</td><td>5.9134</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">English-Albanian</strong> at: <a href='https://wandb.ai/em-city/Translator/runs/15ja72to' target=\"_blank\">https://wandb.ai/em-city/Translator/runs/15ja72to</a><br/> View project at: <a href='https://wandb.ai/em-city/Translator' target=\"_blank\">https://wandb.ai/em-city/Translator</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240519_112651-15ja72to/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "2IwdMxbilubD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(sentence, tokenizer, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer.encode(sentence, return_tensors='pt', max_length=max_len, truncation=True, padding='max_length').to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden, cell = model.encoder(tokens.T)\n",
        "\n",
        "    # Prepare the input and output tensors\n",
        "    trg_indexes = [tokenizer.pad_token_id]\n",
        "    trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor[-1], hidden, cell, encoder_outputs)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tokenizer.pad_token_id:\n",
        "            break\n",
        "\n",
        "        trg_tensor = torch.cat((trg_tensor, torch.LongTensor([pred_token]).unsqueeze(1).to(device)), dim=0)\n",
        "\n",
        "    trg_tokens = tokenizer.decode(trg_indexes, skip_special_tokens=True)\n",
        "    return trg_tokens\n",
        "\n",
        "# Example usage:\n",
        "src_sentence = \"How are you?\"\n",
        "translated_sentence = translate_sentence(src_sentence, tokenizer, model, device)\n",
        "print(f\"Translated Sentence: {translated_sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3wYb39wevIE",
        "outputId": "8693527b-8c1c-4f02-b34a-2a500ce16b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Sentence: ter: Mbëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëëë\n"
          ]
        }
      ]
    }
  ]
}